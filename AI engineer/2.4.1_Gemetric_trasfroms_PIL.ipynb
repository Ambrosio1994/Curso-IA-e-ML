{"cells":[{"cell_type":"markdown","metadata":{"id":"8f7ae686-3fca-48aa-83a8-b95a7a850e18"},"source":["<p>\n","    <a href=\"https://skills.network\" target=\"_blank\">\n","    <img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/assets/logos/SN_web_lightmode.png\" width=\"200\" alt=\"Skills Network Logo\">\n","    </a>\n","</p>\n"]},{"cell_type":"markdown","metadata":{"id":"004c59ad-fff0-428c-909f-ed449af55a32"},"source":["<h1> Geometric Operations and Other Mathematical Tools</h1>\n"]},{"cell_type":"markdown","metadata":{"id":"4d42d5d1-80b1-4d37-9a62-d6848b3c7165"},"source":["Estimated time needed: **40** minutes\n"]},{"cell_type":"markdown","metadata":{"id":"ec4ef8d0-9a63-4385-ad32-2eccfb470440"},"source":["<h2>Objectives</h2>\n"]},{"cell_type":"markdown","metadata":{"id":"4cd809c4-84ac-4d13-af4a-848ca21f3ae1"},"source":["In the first part of the lab, you will apply geometric transformations to an image. This allows you to perform different operations like reshape translation, i.e. to shift, reshape and rotate the image. In the second part of the lab, you will learn how to apply some basic array and matrix operations to the image.\n"]},{"cell_type":"markdown","metadata":{"id":"4e349861-7bb5-4017-95d9-5aa158c1536d"},"source":["<ul>\n","    <li><a href='#PT'> Geometric Operations  </a>\n","        <ul>\n","            <li>Scaling</li>\n","            <li>Translation</li>\n","            <li>Rotation</li>   \n","          </ul>\n","        <li><a href='#PT'>  Mathematical Operations   </a>\n","        <ul>\n","            <li>Array Operations  </li>\n","            <li>Matix Operations n</li>\n","          </ul>\n","\n","\n","</ul>\n"]},{"cell_type":"markdown","metadata":{"id":"dcc6faf1-69c5-4c52-8d30-43f1f70716f7"},"source":["----\n"]},{"cell_type":"markdown","metadata":{"id":"37540e35-d369-4f2f-998f-c2eae9e2026e"},"source":["Download the image for the lab:\n"]},{"cell_type":"code","metadata":{"id":"ec4a8973-75a8-4439-bc82-872be2948720"},"outputs":[],"source":["!wget https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-CV0101EN-SkillsNetwork/images%20/images_part_1/lenna.png -O lenna.png\n","!wget https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-CV0101EN-SkillsNetwork/images%20/images_part_1/baboon.png -O baboon.png\n","!wget https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-CV0101EN-SkillsNetwork/images%20/images_part_1/barbara.png -O barbara.png"],"execution_count":null},{"cell_type":"markdown","metadata":{"id":"ba371167-8c02-48b2-b2ba-f76ff8702b9c"},"source":["We will be using the following imported functions in this lab:\n"]},{"cell_type":"code","metadata":{"id":"f6cb0a2e-b4ab-410e-93f9-8a139ac98832"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","from PIL import Image\n","import numpy as np"],"execution_count":null},{"cell_type":"markdown","metadata":{"id":"72acbf72-24fe-43a9-b60e-04b50df95c2e"},"source":["First, let's define a helper function to plot two images side-by-side. You will not need to understand this code this moment, but this function will be used repeatedly in this tutorial to showcase the results.\n"]},{"cell_type":"code","metadata":{"id":"7c08ac67-98d0-448b-92a4-8bb86c231717"},"outputs":[],"source":["def plot_image(image_1, image_2,title_1=\"Orignal\",title_2=\"New Image\"):\n","    plt.figure(figsize=(10,10))\n","    plt.subplot(1, 2, 1)\n","    plt.imshow(image_1,cmap=\"gray\")\n","    plt.title(title_1)\n","    plt.subplot(1, 2, 2)\n","    plt.imshow(image_2,cmap=\"gray\")\n","    plt.title(title_2)\n","    plt.show()"],"execution_count":null},{"cell_type":"markdown","metadata":{"id":"e4b82b1a-512a-41c1-8cab-2760aff158b0"},"source":["#  Geometric Transformations\n"]},{"cell_type":"markdown","metadata":{"id":"9c4d1386-f8b4-450e-973a-0386d169b4ee"},"source":[" Geometric transformations allow you to perform different operations like translation, i.e. to shift, reshape and rotate the image.\n"]},{"cell_type":"markdown","metadata":{"id":"fe5fdbeb-7c81-4aee-bb3b-9cbf93a2ed8d"},"source":["We can resize an image using the method  <code>resize()</code> of <code>PIL</code> images, which takes the resized image's <code>width</code> and <code>height</code> as paramters.\n","\n","Consider the following image:\n"]},{"cell_type":"code","metadata":{"id":"dc3185db-4b27-4043-b796-dea238d91174"},"outputs":[],"source":["image = Image.open(\"lenna.png\")\n","plt.imshow(image)\n","plt.show()"],"execution_count":null},{"cell_type":"markdown","metadata":{"id":"89080458-eacc-4437-b55b-4477b93b1802"},"source":["We can scale the horizontal axis by two and leave the vertical axis as is:\n"]},{"cell_type":"code","metadata":{"id":"a63ac9d9-4739-45ec-a332-f9ef841e3fc9"},"outputs":[],"source":["width, height = image.size\n","new_width = 2 * width\n","new_hight = height\n","new_image = image.resize((new_width, new_hight))\n","plt.imshow(new_image)\n","plt.show()"],"execution_count":null},{"cell_type":"markdown","metadata":{"id":"73ca1905-7309-4270-b900-e49b7779f33f"},"source":["In the same manner, we can scale the vertical axis by two:\n"]},{"cell_type":"code","metadata":{"id":"16ce9228-fbc9-4e73-b003-adbe749cf63d"},"outputs":[],"source":["new_width = width\n","new_hight = 2 * height\n","new_image = image.resize((new_width, new_hight))\n","plt.imshow(new_image)\n","plt.show()"],"execution_count":null},{"cell_type":"markdown","metadata":{"id":"696a3f8d-0ab0-45c0-8f32-4ed218a18366"},"source":["We can double both the width and the height of the image:\n"]},{"cell_type":"code","metadata":{"id":"630e60eb-457f-4791-af19-9d47da61f2bc"},"outputs":[],"source":["new_width = 2 * width\n","new_hight = 2 * height\n","new_image = image.resize((new_width, new_hight))\n","plt.imshow(new_image)\n","plt.show()"],"execution_count":null},{"cell_type":"markdown","metadata":{"id":"b45c9390-12bb-4b6e-85c5-889a56bf90b9"},"source":["We can also shrink the image's width and height both by 1/2:\n"]},{"cell_type":"code","metadata":{"id":"91783862-5918-43f9-b46a-584ce81f8918"},"outputs":[],"source":["new_width = width // 2\n","new_hight = height // 2\n","\n","new_image = image.resize((new_width, new_hight))\n","plt.imshow(new_image)\n","plt.show()"],"execution_count":null},{"cell_type":"markdown","metadata":{"id":"36aaf8a2-9160-453e-9bf2-f94c7906b5b4"},"source":["## Rotation\n"]},{"cell_type":"markdown","metadata":{"id":"4f113336-2509-4b00-8003-c5bb246ad357"},"source":["We can rotate an image by angle $\\theta$, using the method `rotate`.\n"]},{"cell_type":"markdown","metadata":{"id":"0ab4a8f8-bc45-4af2-b371-ce07cf6e0fb7"},"source":["We can rotate our toy image by 45 degrees:\n"]},{"cell_type":"code","metadata":{"id":"4d8826bc-2146-4e1e-a0dc-23fa904f777b"},"outputs":[],"source":["theta = 45\n","new_image = image.rotate(theta)"],"execution_count":null},{"cell_type":"code","metadata":{"id":"1192ab90-46fa-488a-b223-f17e77bd0e25"},"outputs":[],"source":["plt.imshow(new_image)\n","plt.show()"],"execution_count":null},{"cell_type":"markdown","metadata":{"id":"d4f42c40-802e-480e-b131-354320cafb62"},"source":["# Mathematical Operations\n"]},{"cell_type":"markdown","metadata":{"id":"aa8b7727-d79d-473b-ab36-b0ff2fd4e730"},"source":["## Array Operations\n"]},{"cell_type":"markdown","metadata":{"id":"0a3545ef-d34c-4069-9c2b-bc7619f61b54"},"source":["We can perform array operations on an image; Using Python broadcasting, we can add a constant to each pixel's intensity value.\n","\n","Before doing that, we must first we convert the PIL image to a numpy array.\n"]},{"cell_type":"code","metadata":{"id":"afee2e25-95b0-420c-9f91-3df852afd260"},"outputs":[],"source":["image = np.array(image)"],"execution_count":null},{"cell_type":"markdown","metadata":{"id":"b8e9b610-c9e3-4495-bf9f-f90cedb03e1c"},"source":["We can then add the constant to the image array:\n"]},{"cell_type":"code","metadata":{"id":"a6fd2b6d-270e-4a24-bdf0-552557b174c5"},"outputs":[],"source":["new_image = image + 20\n","plt.imshow(new_image)\n","plt.show()"],"execution_count":null},{"cell_type":"markdown","metadata":{"id":"83a60f9c-58ee-491d-a780-21fa54917375"},"source":["We can also multiply every pixel's intensity value by a constant value.\n"]},{"cell_type":"code","metadata":{"id":"d6965445-5c16-4884-8643-c92c89a41f24"},"outputs":[],"source":["new_image = 10 * image\n","plt.imshow(new_image)\n","plt.show()"],"execution_count":null},{"cell_type":"markdown","metadata":{"id":"6dd4dd92-5f49-4d77-bbc6-a9027a787eea"},"source":["We can add the elements of two arrays of equal shape. In this example, we generate an array of random noises with the same shape and data type as our image.\n"]},{"cell_type":"code","metadata":{"id":"158a0572-110a-4812-97b8-e1ebfd0d9729"},"outputs":[],"source":["Noise = np.random.normal(0, 20, (height, width, 3)).astype(np.uint8)\n","Noise.shape"],"execution_count":null},{"cell_type":"markdown","metadata":{"id":"4695d8de-5243-4f57-94e1-10512d2cf711"},"source":["We add the generated noise to the image and plot the result. We see the values that have corrupted the image:\n"]},{"cell_type":"code","metadata":{"id":"2e632068-8f5a-4ae2-b1ca-d98fbb68d30b"},"outputs":[],"source":["new_image = image + Noise\n","\n","plt.imshow(new_image)\n","plt.show()"],"execution_count":null},{"cell_type":"markdown","metadata":{"id":"9757c9de-f5b5-497f-8709-42488e551c1b"},"source":["At the same time, we can multiply the elements of two arrays of equal shape. We can multiply the random image and the Lenna image and plot the result.\n"]},{"cell_type":"code","metadata":{"id":"6d55cc6e-6fc1-4989-a94a-83d2b8a6ccb0"},"outputs":[],"source":["new_image = image*Noise\n","\n","plt.imshow(new_image)\n","plt.show()"],"execution_count":null},{"cell_type":"markdown","metadata":{"id":"18e91bc8-885c-4953-86c2-780ba19ee892"},"source":["## Matrix Operations\n"]},{"cell_type":"markdown","metadata":{"id":"994e2e26-57a4-451d-ab21-7344b1d95d37"},"source":["Grayscale images are matrices. Consider the following grayscale image:\n"]},{"cell_type":"code","metadata":{"id":"37ba17c5-80e3-4936-a701-b40175cd102c"},"outputs":[],"source":["im_gray = Image.open(\"barbara.png\")"],"execution_count":null},{"cell_type":"markdown","metadata":{"id":"e201fe06-48fb-44f2-a780-3a4d1cacbbf9"},"source":["Even though the image is gray, it has three channels; we can convert it to a one-channel image.\n"]},{"cell_type":"code","metadata":{"id":"d0107f66-712a-4113-a51e-2d3890cc4f77"},"outputs":[],"source":["from PIL import ImageOps"],"execution_count":null},{"cell_type":"code","metadata":{"id":"9786639d-ea27-41c0-bf91-14844b81f2ee"},"outputs":[],"source":["im_gray = ImageOps.grayscale(im_gray)"],"execution_count":null},{"cell_type":"markdown","metadata":{"id":"a1fcccfa-8634-4ee6-97ee-ddb784a53cee"},"source":["We can convert the PIL image to a numpy array:\n"]},{"cell_type":"code","metadata":{"id":"f39ca258-1ab7-4259-9d65-4ba39e1d12f5"},"outputs":[],"source":["im_gray = np.array(im_gray )"],"execution_count":null},{"cell_type":"code","metadata":{"id":"6a9bee87-b6d1-4c7b-98a4-be6943640756"},"outputs":[],"source":["plt.imshow(im_gray,cmap='gray')\n","plt.show()"],"execution_count":null},{"cell_type":"markdown","metadata":{"id":"2cff2e81-8440-4daf-94e1-feca4b24f909"},"source":["We can apply algorithms designed for matrices.  We can use  Singular Value Decomposition, decomposing our image matrix into  a product of three matrices.\n"]},{"cell_type":"code","metadata":{"id":"6d1dab76-f5a5-425b-b6eb-c5395da22037"},"outputs":[],"source":["U, s, V = np.linalg.svd(im_gray , full_matrices=True)"],"execution_count":null},{"cell_type":"markdown","metadata":{"id":"4e75878d-3cf4-4abb-842c-37128b59d220"},"source":["We see <code>s</code> is not rectangular:\n"]},{"cell_type":"code","metadata":{"id":"0e14bf0a-1e4f-4b52-9098-8c2679e4b8a7"},"outputs":[],"source":["s.shape"],"execution_count":null},{"cell_type":"markdown","metadata":{"id":"0bb386b2-75ab-4174-9c6a-428309dd4a88"},"source":["We can convert  <code>s</code> to a diagonal matrix <code>S</code>:\n"]},{"cell_type":"code","metadata":{"id":"d4755d9c-5113-443d-9e54-6958834c7e32"},"outputs":[],"source":["S = np.zeros((im_gray.shape[0], im_gray.shape[1]))\n","S[:image.shape[0], :image.shape[0]] = np.diag(s)"],"execution_count":null},{"cell_type":"markdown","metadata":{"id":"9dfbda2f-4ce1-43b7-b85a-aaf2dc45df76"},"source":["We can plot the matrix U and V:\n"]},{"cell_type":"code","metadata":{"id":"ebceea15-c55a-495d-ae4c-7f222e02cfcf"},"outputs":[],"source":["plot_image(U, V, title_1=\"Matrix U\", title_2=\"Matrix V\")"],"execution_count":null},{"cell_type":"markdown","metadata":{"id":"f63f5fe0-376b-49cc-8b51-43ab7e201b37"},"source":["We see most of the elements in S are zero:\n"]},{"cell_type":"code","metadata":{"id":"957e2bbe-ed87-4aa0-bce2-f162d5b7c78a"},"outputs":[],"source":["plt.imshow(S, cmap='gray')\n","plt.show()"],"execution_count":null},{"cell_type":"markdown","metadata":{"id":"940f8dba-273a-4e7a-a086-f8bf22e5e315"},"source":["We can find the matrix product of all the  matrices. First, we can perform matrix multiplication on S and U and assign it to `B` and plot the results:\n"]},{"cell_type":"code","metadata":{"id":"328e0296-d611-492c-9d7c-e963457b27ab"},"outputs":[],"source":["B = S.dot(V)\n","plt.imshow(B,cmap='gray')\n","plt.show()"],"execution_count":null},{"cell_type":"markdown","metadata":{"id":"6b8727f2-fc05-4775-822f-116cda49afcc"},"source":["We can find the matrix product of `U`, `S`, and `B`. We see it's the entire image:\n"]},{"cell_type":"code","metadata":{"id":"13bc4cf6-9a14-4c6a-a2ef-8dc5bf0ad23b"},"outputs":[],"source":["A = U.dot(B)"],"execution_count":null},{"cell_type":"code","metadata":{"id":"d6cd9dad-e66b-44e6-80cc-2a0a94f68014"},"outputs":[],"source":["plt.imshow(A,cmap='gray')\n","plt.show()"],"execution_count":null},{"cell_type":"markdown","metadata":{"id":"60b0b140-1472-4b59-82a7-8667926d5638"},"source":["It turns out that many elements are redundant. We can eliminate some rows and columns of S and V and approximate the image by finding the product:\n"]},{"cell_type":"code","metadata":{"id":"646e63d6-14bc-411b-bb34-e826fd0f2f84"},"outputs":[],"source":["for n_component in [1,10,100,200, 500]:\n","    S_new = S[:, :n_component]\n","    V_new = V[:n_component, :]\n","    A = U.dot(S_new.dot(V_new))\n","    plt.imshow(A,cmap='gray')\n","    plt.title(\"Number of Components:\"+str(n_component))\n","    plt.show()"],"execution_count":null},{"cell_type":"markdown","metadata":{"id":"05c0895d-6fc3-44cc-8a02-f122e1685835"},"source":["We see we only need 100 to 200 Components to represent the image.\n"]},{"cell_type":"markdown","metadata":{"id":"64701d3c-f5be-4bee-807a-1218c6bc721e"},"source":["<h2>Authors</h2>\n"]},{"cell_type":"markdown","metadata":{"id":"570fc90a-bb4b-4e9e-88cd-adb54054fe1e"},"source":[" [Joseph Santarcangelo]( https://www.linkedin.com/in/joseph-s-50398b136/) has a PhD in Electrical Engineering, his research focused on using machine learning, signal processing, and computer vision to determine how videos impact human cognition. Joseph has been working for IBM since he completed his PhD.\n"]},{"cell_type":"markdown","metadata":{"id":"f43eb03d-5790-4fd5-be74-125467818feb"},"source":["# References\n"]},{"cell_type":"markdown","metadata":{"id":"70e4d200-286e-409f-bb39-e4d5acb02344"},"source":["[1]  Images were taken from: https://homepages.cae.wisc.edu/~ece533/images/\n","    \n","[2]  <a href='https://pillow.readthedocs.io/en/stable/index.html'>Pillow Docs</a>\n","\n","[3]  <a href='https://opencv.org/'>Open CV</a>\n","\n","[4] Gonzalez, Rafael C., and Richard E. Woods. \"Digital image processing.\" (2017).\n","\n","[5 ] Jian, Wushuai, Xueyan Sun, and Shuqian Luo. \"Computer-aided diagnosis of breast microcalcifications based on dual-tree complex wavelet transform.\" Biomedical engineering online 11.1 (2012): 1-12.\n"]},{"cell_type":"markdown","metadata":{"id":"04459589-cfed-4a88-97a4-22f2b96c3ef4"},"source":["<!--<h2>Change Log</h2>-->\n"]},{"cell_type":"markdown","metadata":{"id":"b9ef0dee-6db1-44c8-9c04-eafe1a91137d"},"source":["<!--<table>\n","    <tr>\n","        <th>Date (YYYY-MM-DD)</th>\n","        <th>Version</th>\n","        <th>Changed By</th>\n","        <th>Change Description</th>\n","    </tr>\n","    <tr>\n","        <td>2020-07-20</td>\n","        <td>0.2</td>\n","        <td>Azim</td>\n","        <td>Modified Multiple Areas</td>\n","    </tr>\n","    <tr>\n","        <td>2020-07-17</td>\n","        <td>0.1</td>\n","        <td>Azim</td>\n","        <td>Created Lab Template</td>\n","    </tr>\n","</table>\n","-->\n"]},{"cell_type":"markdown","metadata":{"id":"2aecffdd-b5bb-429c-9e1d-462621473518"},"source":["<h3 align=\"center\"> &#169; IBM Corporation. All rights reserved. <h3/>\n"]}],"metadata":{"kernelspec":{"display_name":"Python","language":"python","name":"conda-env-python-py"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"prev_pub_hash":"3c6dcfa15b12d3e01bb0b46e052299dac9cd7bf2564f6289d09136c880fb23b9","colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}