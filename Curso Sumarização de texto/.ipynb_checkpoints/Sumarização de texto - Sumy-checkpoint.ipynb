{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "96da28f1-7a59-4ea9-aad7-9c9b6d14ffb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\diham\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from goose3 import Goose\n",
    "\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "da93938c-689d-47c7-ab23-1cbe87abf27d",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = Goose()\n",
    "url = 'https://iaexpert.academy/2020/11/09/ia-preve-resultado-das-eleicoes-americanas/'\n",
    "artigo_portugues = g.extract(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a7e63dc1-6ab7-407a-b7bb-2beb46fffb1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://en.wikipedia.org/wiki/Artificial_intelligence'\n",
    "artigo_ingles = g.extract(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e9d814f3-5a11-4c11-84cc-bf1b23577264",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Nas eleições presidenciais americanas de 2016, a maioria das predições apontavam para a vitória de Hillary Clinton. Entretanto, a história nos mostrou o resultado oposto, e Donald Trump foi o presidente nos últimos 4 anos. Desta vez, os estatísticos reexaminaram seus modelos, para aumentar o grau de confiabilidade nos seus resultados. Nesta tentativa de otimização das predições, a inteligência artificial certamente não ficou de fora.\\n\\nO modelo desenvolvido pelo Dr. Hernan Makse, físico estatístico da Universidade da Cidade de Nova York, baseou suas predições em uma rede neural treinada para processar os sentimentos expressos nas redes sociais. O algoritmo fez a análise de cerca de 1 bilhão de tweets para chegar a uma estimativa dos resultados do pleito. No dia da eleição, 3 de novembro, o modelo estava indicando a vitória de Joe Biden.\\n\\nO Dr. Makse disse que seu trabalho começou já na eleição de 2016, e foi testado novamente nas eleições na Argentina ano passado. Desta vez, o modelo está treinando com cerca de 5 vezes mais dados que nas eleições americanas anteriores. O trabalho não depende apenas da coleta dos dados, mas também de um tratamento estatístico adequado para levar em consideração duas variáveis externas: o viés de amostragem e a taxa de comparecimento. O primeiro fator se refere ao fato de que as redes sociais não necessariamente representam a população americana. A participação em redes sociais costuma ser maior nas cidades grandes, que de fato têm preferência por um dos candidatos, e o modelo deve ser corrigido para levar em consideração também a opinião das pessoas que não são ativas neste ambiente virtual. O segundo fator se deve à não-obrigatoriedade de votação nos Estados Unidos, ou seja, por mais que uma pessoa tenha sua preferência, pode ser que ela não compareça aos locais de votação para efetivá-la. Segundo o Dr. Makse, integrar estas duas variáveis em seu modelo é a parte mais importante do trabalho. Ele acredita ser esta uma das razões para que as estimativas da última eleição, baseadas em métodos tradicionais de coleta de informação, terem falhado. Sua equipe acompanhou as tendências apresentadas nas últimas eleições na Europa, e os modelos estão se revelando cada vez melhores.\\n\\nQuando seu modelo foi usado para predizer os resultados da eleição corrente usando dados brutos, Joe Biden apareceu como vencedor com larga vantagem. Após aplicar os mecanismos de correção para os dois vieses identificados, a vantagem diminuiu, mas Biden ainda é indicado como favorito.\\n\\nParece que, desta vez, os algoritmos estão de fato contribuindo para que as predições sejam mais precisas.'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "artigo_portugues.cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0ee9d333-6ab2-47c4-a488-affe29fbf139",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sumy\n",
      "  Downloading sumy-0.11.0-py2.py3-none-any.whl (97 kB)\n",
      "     ---------------------------------------- 0.0/97.3 kB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/97.3 kB ? eta -:--:--\n",
      "     ---- ----------------------------------- 10.2/97.3 kB ? eta -:--:--\n",
      "     ---- ----------------------------------- 10.2/97.3 kB ? eta -:--:--\n",
      "     ----------- -------------------------- 30.7/97.3 kB 220.2 kB/s eta 0:00:01\n",
      "     --------------- ---------------------- 41.0/97.3 kB 245.8 kB/s eta 0:00:01\n",
      "     -------------------------------------- 97.3/97.3 kB 429.0 kB/s eta 0:00:00\n",
      "Collecting docopt<0.7,>=0.6.1 (from sumy)\n",
      "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting breadability>=0.1.20 (from sumy)\n",
      "  Downloading breadability-0.1.20.tar.gz (32 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: requests>=2.7.0 in c:\\users\\diham\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sumy) (2.31.0)\n",
      "Collecting pycountry>=18.2.23 (from sumy)\n",
      "  Downloading pycountry-22.3.5.tar.gz (10.1 MB)\n",
      "     ---------------------------------------- 0.0/10.1 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.1/10.1 MB 3.3 MB/s eta 0:00:04\n",
      "     - -------------------------------------- 0.3/10.1 MB 3.2 MB/s eta 0:00:04\n",
      "     - -------------------------------------- 0.4/10.1 MB 3.7 MB/s eta 0:00:03\n",
      "     -- ------------------------------------- 0.6/10.1 MB 3.5 MB/s eta 0:00:03\n",
      "     -- ------------------------------------- 0.8/10.1 MB 3.4 MB/s eta 0:00:03\n",
      "     --- ------------------------------------ 0.9/10.1 MB 3.7 MB/s eta 0:00:03\n",
      "     ---- ----------------------------------- 1.1/10.1 MB 3.5 MB/s eta 0:00:03\n",
      "     ----- ---------------------------------- 1.3/10.1 MB 3.6 MB/s eta 0:00:03\n",
      "     ----- ---------------------------------- 1.4/10.1 MB 3.5 MB/s eta 0:00:03\n",
      "     ------ --------------------------------- 1.6/10.1 MB 3.5 MB/s eta 0:00:03\n",
      "     ------- -------------------------------- 1.8/10.1 MB 3.6 MB/s eta 0:00:03\n",
      "     ------- -------------------------------- 2.0/10.1 MB 3.6 MB/s eta 0:00:03\n",
      "     -------- ------------------------------- 2.2/10.1 MB 3.7 MB/s eta 0:00:03\n",
      "     --------- ------------------------------ 2.4/10.1 MB 3.9 MB/s eta 0:00:03\n",
      "     --------- ------------------------------ 2.5/10.1 MB 3.7 MB/s eta 0:00:03\n",
      "     ---------- ----------------------------- 2.7/10.1 MB 3.7 MB/s eta 0:00:02\n",
      "     ----------- ---------------------------- 2.9/10.1 MB 3.7 MB/s eta 0:00:02\n",
      "     ----------- ---------------------------- 3.0/10.1 MB 3.6 MB/s eta 0:00:02\n",
      "     ------------ --------------------------- 3.2/10.1 MB 3.7 MB/s eta 0:00:02\n",
      "     ------------- -------------------------- 3.4/10.1 MB 3.7 MB/s eta 0:00:02\n",
      "     ------------- -------------------------- 3.5/10.1 MB 3.7 MB/s eta 0:00:02\n",
      "     -------------- ------------------------- 3.7/10.1 MB 3.7 MB/s eta 0:00:02\n",
      "     --------------- ------------------------ 3.8/10.1 MB 3.7 MB/s eta 0:00:02\n",
      "     --------------- ------------------------ 4.0/10.1 MB 3.7 MB/s eta 0:00:02\n",
      "     ---------------- ----------------------- 4.2/10.1 MB 3.7 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 4.4/10.1 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 4.5/10.1 MB 3.6 MB/s eta 0:00:02\n",
      "     ------------------ --------------------- 4.8/10.1 MB 3.7 MB/s eta 0:00:02\n",
      "     ------------------- -------------------- 5.0/10.1 MB 3.8 MB/s eta 0:00:02\n",
      "     -------------------- ------------------- 5.2/10.1 MB 3.8 MB/s eta 0:00:02\n",
      "     --------------------- ------------------ 5.4/10.1 MB 3.8 MB/s eta 0:00:02\n",
      "     ---------------------- ----------------- 5.7/10.1 MB 3.8 MB/s eta 0:00:02\n",
      "     ----------------------- ---------------- 5.9/10.1 MB 3.9 MB/s eta 0:00:02\n",
      "     ----------------------- ---------------- 6.1/10.1 MB 3.9 MB/s eta 0:00:02\n",
      "     ------------------------ --------------- 6.3/10.1 MB 3.9 MB/s eta 0:00:01\n",
      "     ------------------------- -------------- 6.6/10.1 MB 4.0 MB/s eta 0:00:01\n",
      "     -------------------------- ------------- 6.8/10.1 MB 4.0 MB/s eta 0:00:01\n",
      "     --------------------------- ------------ 7.0/10.1 MB 4.0 MB/s eta 0:00:01\n",
      "     ---------------------------- ----------- 7.2/10.1 MB 4.0 MB/s eta 0:00:01\n",
      "     ----------------------------- ---------- 7.5/10.1 MB 4.0 MB/s eta 0:00:01\n",
      "     ------------------------------ --------- 7.7/10.1 MB 4.1 MB/s eta 0:00:01\n",
      "     ------------------------------- -------- 7.9/10.1 MB 4.1 MB/s eta 0:00:01\n",
      "     ------------------------------- -------- 8.1/10.1 MB 4.1 MB/s eta 0:00:01\n",
      "     -------------------------------- ------- 8.3/10.1 MB 4.1 MB/s eta 0:00:01\n",
      "     --------------------------------- ------ 8.5/10.1 MB 4.1 MB/s eta 0:00:01\n",
      "     ---------------------------------- ----- 8.7/10.1 MB 4.1 MB/s eta 0:00:01\n",
      "     ---------------------------------- ----- 8.9/10.1 MB 4.1 MB/s eta 0:00:01\n",
      "     ----------------------------------- ---- 9.0/10.1 MB 4.1 MB/s eta 0:00:01\n",
      "     ------------------------------------ --- 9.2/10.1 MB 4.1 MB/s eta 0:00:01\n",
      "     ------------------------------------- -- 9.5/10.1 MB 4.1 MB/s eta 0:00:01\n",
      "     -------------------------------------- - 9.7/10.1 MB 4.1 MB/s eta 0:00:01\n",
      "     ---------------------------------------  9.9/10.1 MB 4.1 MB/s eta 0:00:01\n",
      "     ---------------------------------------  10.1/10.1 MB 4.1 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 10.1/10.1 MB 4.1 MB/s eta 0:00:00\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Requirement already satisfied: nltk>=3.0.2 in c:\\users\\diham\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sumy) (3.8.1)\n",
      "Collecting chardet (from breadability>=0.1.20->sumy)\n",
      "  Downloading chardet-5.2.0-py3-none-any.whl.metadata (3.4 kB)\n",
      "Requirement already satisfied: lxml>=2.0 in c:\\users\\diham\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from breadability>=0.1.20->sumy) (4.9.3)\n",
      "Requirement already satisfied: click in c:\\users\\diham\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nltk>=3.0.2->sumy) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\diham\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nltk>=3.0.2->sumy) (1.3.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\diham\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nltk>=3.0.2->sumy) (2023.10.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\diham\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nltk>=3.0.2->sumy) (4.66.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\diham\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pycountry>=18.2.23->sumy) (65.5.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\diham\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.7.0->sumy) (3.3.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\diham\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.7.0->sumy) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\diham\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.7.0->sumy) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\diham\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.7.0->sumy) (2023.7.22)\n",
      "Requirement already satisfied: colorama in c:\\users\\diham\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from click->nltk>=3.0.2->sumy) (0.4.6)\n",
      "Downloading chardet-5.2.0-py3-none-any.whl (199 kB)\n",
      "   ---------------------------------------- 0.0/199.4 kB ? eta -:--:--\n",
      "   ---------------------------------------- 199.4/199.4 kB 6.1 MB/s eta 0:00:00\n",
      "Building wheels for collected packages: breadability, docopt, pycountry\n",
      "  Building wheel for breadability (setup.py): started\n",
      "  Building wheel for breadability (setup.py): finished with status 'done'\n",
      "  Created wheel for breadability: filename=breadability-0.1.20-py2.py3-none-any.whl size=21739 sha256=02f408cfb020ee77043adb039289d38e3b5109da202fb6ac849bc0b8b455d928\n",
      "  Stored in directory: c:\\users\\diham\\appdata\\local\\pip\\cache\\wheels\\4d\\57\\58\\7e3d7fedf51fe248b7fcee3df6945ae28638e22cddf01eb92b\n",
      "  Building wheel for docopt (setup.py): started\n",
      "  Building wheel for docopt (setup.py): finished with status 'done'\n",
      "  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13773 sha256=d14dd67c66c8b28b4ad80925584c5a695c9d54df61d6e37aa896406745f96682\n",
      "  Stored in directory: c:\\users\\diham\\appdata\\local\\pip\\cache\\wheels\\1a\\b0\\8c\\4b75c4116c31f83c8f9f047231251e13cc74481cca4a78a9ce\n",
      "  Building wheel for pycountry (pyproject.toml): started\n",
      "  Building wheel for pycountry (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for pycountry: filename=pycountry-22.3.5-py2.py3-none-any.whl size=10681896 sha256=ef6f081c33bc0463dd6589a810b922cc9d32b18d5f2d7cd09b78ccac0f885678\n",
      "  Stored in directory: c:\\users\\diham\\appdata\\local\\pip\\cache\\wheels\\cd\\29\\8b\\617685ed7942656b36efb06ff9247dbe832e3f4f7724fffc09\n",
      "Successfully built breadability docopt pycountry\n",
      "Installing collected packages: docopt, pycountry, chardet, breadability, sumy\n",
      "Successfully installed breadability-0.1.20 chardet-5.2.0 docopt-0.6.2 pycountry-22.3.5 sumy-0.11.0\n"
     ]
    }
   ],
   "source": [
    "!pip install sumy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "93c0203b-7bf4-45fe-88c9-3de498ad13b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sumy.parsers.plaintext import PlaintextParser\n",
    "from sumy.nlp.tokenizers import Tokenizer\n",
    "from sumy.summarizers.luhn import LuhnSummarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0f82b7ae-83c7-4bff-93c3-45dc7a6c93e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = PlaintextParser.from_string(artigo_portugues.cleaned_text, Tokenizer('portuguese'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "95bd9a2c-bf0e-418f-8e09-7a586ec4191c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sumarizador = LuhnSummarizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8904b55e-062a-41c7-ad3b-30d34bb4905a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<Sentence: Desta vez, o modelo está treinando com cerca de 5 vezes mais dados que nas eleições americanas anteriores.>,\n",
       " <Sentence: O trabalho não depende apenas da coleta dos dados, mas também de um tratamento estatístico adequado para levar em consideração duas variáveis externas: o viés de amostragem e a taxa de comparecimento.>,\n",
       " <Sentence: A participação em redes sociais costuma ser maior nas cidades grandes, que de fato têm preferência por um dos candidatos, e o modelo deve ser corrigido para levar em consideração também a opinião das pessoas que não são ativas neste ambiente virtual.>,\n",
       " <Sentence: Segundo o Dr. Makse, integrar estas duas variáveis em seu modelo é a parte mais importante do trabalho.>,\n",
       " <Sentence: Parece que, desta vez, os algoritmos estão de fato contribuindo para que as predições sejam mais precisas.>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resumo = sumarizador(parser.document, 5)\n",
    "resumo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bb8677cb-0db0-4748-9ef9-1a33ea647f2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Desta vez, o modelo está treinando com cerca de 5 vezes mais dados que nas eleições americanas anteriores.\n",
      "O trabalho não depende apenas da coleta dos dados, mas também de um tratamento estatístico adequado para levar em consideração duas variáveis externas: o viés de amostragem e a taxa de comparecimento.\n",
      "A participação em redes sociais costuma ser maior nas cidades grandes, que de fato têm preferência por um dos candidatos, e o modelo deve ser corrigido para levar em consideração também a opinião das pessoas que não são ativas neste ambiente virtual.\n",
      "Segundo o Dr. Makse, integrar estas duas variáveis em seu modelo é a parte mais importante do trabalho.\n",
      "Parece que, desta vez, os algoritmos estão de fato contribuindo para que as predições sejam mais precisas.\n"
     ]
    }
   ],
   "source": [
    "for sentença in resumo:\n",
    "    print(sentença)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
