{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPIjRNccLBm2Jr0u0+xsDGb"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["import numpy as np"],"metadata":{"id":"P9ztMXxhYzrd","executionInfo":{"status":"ok","timestamp":1716489187876,"user_tz":180,"elapsed":11,"user":{"displayName":"DIEGO AMBROSIO","userId":"04645390355005059837"}}},"execution_count":1,"outputs":[]},{"cell_type":"code","source":["# Função para selecionar a ação com o valor máximo\n","def argmax(q_values):\n","    top_value = float(\"-inf\")\n","    ties = []\n","\n","    for i in range(len(q_values)):\n","        if q_values[i] > top_value:\n","            top_value = q_values[i]\n","            ties = [i]\n","        elif q_values[i] == top_value:\n","            ties.append(i)\n","\n","    return np.random.choice(ties)"],"metadata":{"id":"EzU20lKGZzTn","executionInfo":{"status":"ok","timestamp":1716489187878,"user_tz":180,"elapsed":12,"user":{"displayName":"DIEGO AMBROSIO","userId":"04645390355005059837"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["q_values = [4, 1, 3, 4, 2, 4, 0, 4]\n","argmax(q_values)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"a5skp7MgZ1Mz","executionInfo":{"status":"ok","timestamp":1716489187878,"user_tz":180,"elapsed":11,"user":{"displayName":"DIEGO AMBROSIO","userId":"04645390355005059837"}},"outputId":"ec765da5-7ea7-4c22-af3d-ae83e09f3650"},"execution_count":3,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0"]},"metadata":{},"execution_count":3}]},{"cell_type":"code","source":["num_states = 5\n","num_actions = 2\n","gamma = 0.9  # Fator de desconto\n","alpha = 0.1  # Taxa de aprendizado\n","num_episodes = 20"],"metadata":{"id":"ST_nkT3EY-IM","executionInfo":{"status":"ok","timestamp":1716489291168,"user_tz":180,"elapsed":309,"user":{"displayName":"DIEGO AMBROSIO","userId":"04645390355005059837"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["# Inicializa a tabela Q com zeros\n","Q = np.zeros((num_states, num_actions))\n","print(f\"Número de Linhas {Q.shape[0]}\\nNúmero de Colunas {Q.shape[1]}\")\n","print(Q)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uiB14nqdZCUl","executionInfo":{"status":"ok","timestamp":1716489188314,"user_tz":180,"elapsed":445,"user":{"displayName":"DIEGO AMBROSIO","userId":"04645390355005059837"}},"outputId":"70e8d6c3-db01-47d6-ce7a-9545714184d0"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Número de Linhas 5\n","Número de Colunas 2\n","[[0. 0.]\n"," [0. 0.]\n"," [0. 0.]\n"," [0. 0.]\n"," [0. 0.]]\n"]}]},{"cell_type":"code","source":["print(np.random.uniform(0, 1))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mmeFiRFpZ1Jx","executionInfo":{"status":"ok","timestamp":1716489188314,"user_tz":180,"elapsed":21,"user":{"displayName":"DIEGO AMBROSIO","userId":"04645390355005059837"}},"outputId":"f218cc30-57a8-49e2-dcbd-bbeb014c9e7c"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["0.7229740421639774\n"]}]},{"cell_type":"code","source":["num_actions = 2\n","np.random.choice(num_actions)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Gd-iGnr-ZFQp","executionInfo":{"status":"ok","timestamp":1716489188314,"user_tz":180,"elapsed":17,"user":{"displayName":"DIEGO AMBROSIO","userId":"04645390355005059837"}},"outputId":"5a63669a-9a27-4f07-9b7a-64bb5adb88d3"},"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1"]},"metadata":{},"execution_count":7}]},{"cell_type":"code","source":["def choose_action(state, epsilon):\n","    \"\"\"\n","    Escolhe uma ação com base na estratégia epsilon-greedy\n","\n","    Parâmetros:\n","    state (int): O estado atual do agente\n","    epsilon (float): A probabilidade de explorar (escolher uma ação aleatória)\n","\n","    Retorna:\n","    int: O índice da ação escolhida\n","    \"\"\"\n","\n","    # Verifica se deve explorar\n","    if np.random.uniform(0, 1) < epsilon:\n","        # Exploração: escolhe uma ação aleatória\n","        return np.random.choice(num_actions)\n","    else:\n","        # Exploração: escolhe a melhor ação conhecida\n","        return argmax(Q[state, :])"],"metadata":{"id":"Ku_4AXH9gEsB","executionInfo":{"status":"ok","timestamp":1716489188314,"user_tz":180,"elapsed":15,"user":{"displayName":"DIEGO AMBROSIO","userId":"04645390355005059837"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["state = np.random.randint(0, num_states) # Estado inicial aleatório\n","state"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hctl2dQ1gf30","executionInfo":{"status":"ok","timestamp":1716489188315,"user_tz":180,"elapsed":15,"user":{"displayName":"DIEGO AMBROSIO","userId":"04645390355005059837"}},"outputId":"8b4745a1-5335-41d1-b33f-25028a45d019"},"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"text/plain":["3"]},"metadata":{},"execution_count":10}]},{"cell_type":"code","source":["epsilon = 0.1\n","action  = choose_action(state, epsilon) # Seleciona ação\n","action"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Gr37kXicciir","executionInfo":{"status":"ok","timestamp":1716489188315,"user_tz":180,"elapsed":13,"user":{"displayName":"DIEGO AMBROSIO","userId":"04645390355005059837"}},"outputId":"4344a8d5-3794-43d8-e6ac-ed0f962e7163"},"execution_count":11,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0"]},"metadata":{},"execution_count":11}]},{"cell_type":"code","source":["for episode in range(5):\n","    state = np.random.randint(0, num_states)  # Estado inicial aleatório\n","    print(f\"Estado inicial aleatório: {state}\")\n","    epsilon = 1.0 / (episode + 1)  # Decaimento de epsilon\n","    print(f\"epsilon {epsilon}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7Xq27kloh9z7","executionInfo":{"status":"ok","timestamp":1716489358229,"user_tz":180,"elapsed":351,"user":{"displayName":"DIEGO AMBROSIO","userId":"04645390355005059837"}},"outputId":"7bb578b8-6dad-4aeb-bf23-5309fd9ed080"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["Estado inicial aleatório: 2\n","epsilon 1.0\n","Estado inicial aleatório: 4\n","epsilon 0.5\n","Estado inicial aleatório: 3\n","epsilon 0.3333333333333333\n","Estado inicial aleatório: 4\n","epsilon 0.25\n","Estado inicial aleatório: 0\n","epsilon 0.2\n"]}]},{"cell_type":"code","source":["# Função de atualização Q-learning\n","def q(Q, alpha, R):\n","    # Atualiza o valor Q usando a fórmula do Q-learning\n","    # Q: valor Q atual\n","    # alpha: taxa de aprendizado\n","    # R: recompensa observada\n","    return Q + alpha * (R - Q)"],"metadata":{"id":"Nl4VdySP9v8d","executionInfo":{"status":"ok","timestamp":1716493512042,"user_tz":180,"elapsed":489,"user":{"displayName":"DIEGO AMBROSIO","userId":"04645390355005059837"}}},"execution_count":29,"outputs":[]},{"cell_type":"code","source":["Q = 2\n","alpha = 0.5\n","R = 1\n","\n","q(Q, alpha, R)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rzq2l2EK-Oaz","executionInfo":{"status":"ok","timestamp":1716493506916,"user_tz":180,"elapsed":8,"user":{"displayName":"DIEGO AMBROSIO","userId":"04645390355005059837"}},"outputId":"4f9dd268-39c2-4c26-9027-d93592f0e5b7"},"execution_count":28,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1.5"]},"metadata":{},"execution_count":28}]},{"cell_type":"code","source":["2 + 0.5*(1-2)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Aa3qEHHhh9uT","executionInfo":{"status":"ok","timestamp":1716491303100,"user_tz":180,"elapsed":477,"user":{"displayName":"DIEGO AMBROSIO","userId":"04645390355005059837"}},"outputId":"42a87dc2-9175-4f30-8c8b-b8b530eb2d15"},"execution_count":18,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1.5"]},"metadata":{},"execution_count":18}]},{"cell_type":"code","source":["# Simulação do ambiente (exemplo simples)\n","def simulate_environment(state, action):\n","    # Calcula o próximo estado baseado no estado atual e na ação\n","    next_state = (state + action) % num_states\n","\n","    # Define a recompensa: 1 se o próximo estado for igual ao último estado (num_states - 1),\n","    #  caso contrário 0\n","    reward = 1 if next_state == num_states - 1 else 0\n","\n","    # Retorna o próximo estado e a recompensa\n","    return next_state, reward"],"metadata":{"id":"Xi4No3v2h99i","executionInfo":{"status":"ok","timestamp":1716489188314,"user_tz":180,"elapsed":15,"user":{"displayName":"DIEGO AMBROSIO","userId":"04645390355005059837"}}},"execution_count":9,"outputs":[]}]}