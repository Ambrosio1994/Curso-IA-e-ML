{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOM8Ai0QxWuWIW0iJnglukp"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["Monte Carlo é um conjunto de métodos utilizados para estimar valores de funções de recompensa ao longo do tempo, baseando-se em amostragens repetidas de trajetórias de episódios completos.\n","\n","Esses métodos envolvem a simulação de múltiplas \"jogadas\" completas (ou episódios) dentro do ambiente, onde cada jogada vai do estado inicial até o estado final. Ao final de cada episódio, a recompensa total acumulada é utilizada para atualizar as estimativas das recompensas esperadas para os estados e ações visitados durante o episódio."],"metadata":{"id":"5aBu_fxG43iw"}},{"cell_type":"markdown","source":["<h1>Monte Carlo Exploring Starts</h1>"],"metadata":{"id":"VIz6bjTMntMS"}},{"cell_type":"code","execution_count":1,"metadata":{"id":"K7lGE0Wl4tWJ","executionInfo":{"status":"ok","timestamp":1716929194122,"user_tz":180,"elapsed":464,"user":{"displayName":"DIEGO AMBROSIO","userId":"04645390355005059837"}}},"outputs":[],"source":["import numpy as np\n","\n","# Parâmetros\n","num_states = 5\n","num_episodes = 1000\n","gamma = 0.9  # Fator de desconto"]},{"cell_type":"code","source":["# Inicialização\n","V = np.zeros(num_states)\n","returns = {state: [] for state in range(num_states)}"],"metadata":{"id":"nEUBtWNq48r9","executionInfo":{"status":"ok","timestamp":1716929195066,"user_tz":180,"elapsed":10,"user":{"displayName":"DIEGO AMBROSIO","userId":"04645390355005059837"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["# Função de transição do ambiente (simplificada)\n","def transition(state, action):\n","    if action == 0:\n","        next_state = (state + 1) % num_states  # Exemplo de transição\n","    else:\n","        next_state = (state - 1) % num_states  # Exemplo de transição\n","    reward = np.random.randn()  # Recompensa aleatória\n","    return next_state, reward"],"metadata":{"id":"ujszUKYXos0e","executionInfo":{"status":"ok","timestamp":1716929195066,"user_tz":180,"elapsed":9,"user":{"displayName":"DIEGO AMBROSIO","userId":"04645390355005059837"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["# Política simples (pode ser aleatória para começar)\n","def policy(state, num_actions=2):\n","    return np.random.choice(num_actions)"],"metadata":{"id":"X1EX4gcPvlwX","executionInfo":{"status":"ok","timestamp":1716929195066,"user_tz":180,"elapsed":9,"user":{"displayName":"DIEGO AMBROSIO","userId":"04645390355005059837"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["# Função para simular um episódio (exemplo)\n","def simulate_episode():\n","    episode = []\n","    state = np.random.randint(0, num_states) # Estado inicial aleatório\n","    while state != 4:  # Suponha que o estado 4 é o estado terminal\n","        action = policy(state)\n","        next_state, reward = transition(state, action)\n","        reward = np.random.randn()  # Recompensa aleatória\n","        episode.append((state, reward))\n","        state = next_state\n","    return episode"],"metadata":{"id":"65mfiiLU56i6","executionInfo":{"status":"ok","timestamp":1716929195066,"user_tz":180,"elapsed":9,"user":{"displayName":"DIEGO AMBROSIO","userId":"04645390355005059837"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["# Método Monte Carlo\n","for _ in range(num_episodes):\n","    episode = simulate_episode()\n","    G = 0  # Retorno inicial\n","    for state, reward in reversed(episode):\n","        G = reward + gamma * G\n","        returns[state].append(G)\n","        V[state] = np.mean(returns[state])\n","\n","print(\"Estimativa da função valor V(s):\")\n","print(V)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9xnTrRjU6Asy","executionInfo":{"status":"ok","timestamp":1716929195067,"user_tz":180,"elapsed":9,"user":{"displayName":"DIEGO AMBROSIO","userId":"04645390355005059837"}},"outputId":"a78d5836-d4bf-4efd-d38a-5e69585a1331"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Estimativa da função valor V(s):\n","[ 0.10101402  0.09714746  0.01654311 -0.01833288  0.        ]\n"]}]}]}