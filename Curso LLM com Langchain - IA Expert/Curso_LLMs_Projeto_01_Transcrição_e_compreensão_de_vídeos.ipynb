{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f3MLuFhHBpOr"
      },
      "source": [
        "# Projeto 01 - Transcrição e compreensão de vídeos\n",
        "\n",
        "Neste projeto, vamos aprender a realizar transcrição e compreensão de vídeos. Ao final, você será capaz de criar sua própria aplicação que faz a sumarização automática de vídeos, permitindo que você entenda do que se trata e o que foi falado nele sem precisar assistí-lo.\n",
        "\n",
        "Objetivos deste projeto:\n",
        "\n",
        "* Compreender o conteúdo de um vídeo do Youtube sem precisar assisti-lo.\n",
        "* Pesquisar informações úteis no vídeo sem perder nenhum detalhe importante.\n",
        "* Interagir com o conteúdo do vídeo por meio de uma interface de chat (ou seja, como \"conversar com o vídeo\")."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JJ9gpWgBDV7y"
      },
      "source": [
        "## Instalação e Configuração"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q langchain_community langchain-huggingface langchain_ollama langchain_openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xzc8u4SnL5Io",
        "outputId": "681a302c-0d98-4b7b-bd2a-436a21a4bf59"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m23.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.4/50.4 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m20.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m408.7/408.7 kB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m32.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m30.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.5/49.5 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nSLHzeWUt-S2"
      },
      "source": [
        "### Instalação de bibliotecas para baixar transcrição\n",
        "\n",
        "> **YouTube Transcript API**\n",
        "\n",
        "Esta é uma API python que permite que você obtenha a transcrição/legendas para um determinado vídeo do YouTube. Ela também funciona para legendas geradas automaticamente e possui suporta a uma função que faz automaticamente a tradução de legendas"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install youtube-transcript-api"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GBMK_nzjMXzr",
        "outputId": "14f20152-3a3e-47e5-a4e6-906de35770db"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting youtube-transcript-api\n",
            "  Downloading youtube_transcript_api-0.6.2-py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from youtube-transcript-api) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->youtube-transcript-api) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->youtube-transcript-api) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->youtube-transcript-api) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->youtube-transcript-api) (2024.8.30)\n",
            "Downloading youtube_transcript_api-0.6.2-py3-none-any.whl (24 kB)\n",
            "Installing collected packages: youtube-transcript-api\n",
            "Successfully installed youtube-transcript-api-0.6.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GlGwCqzdvHfy"
      },
      "source": [
        "> **pytube**\n",
        "\n",
        "Também é uma biblioteca que auxilia com o download de vídeos no youtube. Aqui ela não é necessária para baixar as transcrições dos vídeos, conseguimos ter acesso sem ela, mas iremos instalar também pois com ela podemos recuperar também demais informações do vídeo, como título, data de publicação, descrição, etc."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install pytube\n",
        "!pip install --upgrade pytube"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Z3a89t8MhFQ",
        "outputId": "d806adf4-244d-4d97-cfea-ed228f56efe3"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pytube in /usr/local/lib/python3.10/dist-packages (15.0.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "raKvr8oow-yL"
      },
      "source": [
        "## Importações"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import io\n",
        "import getpass\n",
        "from langchain_community.document_loaders import YoutubeLoader\n",
        "from langchain_community.llms import HuggingFaceHub\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.output_parsers import StrOutputParser"
      ],
      "metadata": {
        "id": "0KsvbMvhMv2x"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G0DTTSc_t7vA"
      },
      "source": [
        "## Carregando a transcrição\n",
        "\n",
        "Para fazer o carregamento das transcrições usaremos o método YoutubeLoader(), que faz parte do dos document_loaders do LangChain. Veremos logo em seguida também como extrair os metadados do vídeo usando essa função\n",
        "\n",
        "Através desses método conseguimos puxar as transcrições que já estão associadas ao vídeo e armazenadas no banco de dados do Youtube, o que irá nos economizar bastante processamento.\n",
        "\n",
        "\n",
        "O primeiro parâmetro é a URL do vídeo que queremos realizar a transcrição\n",
        "\n",
        "Vamos pegar esse vídeo como primeiro exemplo https://www.youtube.com/watch?v=II28i__Tf3M"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Defininido idiomas\n",
        "\n",
        "O segundo parâmetro é o language. A função espera uma lista, nesse caso, uma lista de códigos de idioma em prioridade decrescente (por padrão).\n",
        "\n",
        "Além de inglês (\"en\"), recomendamos deixar antes \"pt\" e \"pt-BR\" (ou \"pt-PT\") pois em alguns vídeos não possui \"pt\". Embora a grande maioria dos vídeos que testamos possua legenda com código \"pt\", mesmo para vídeos com a legenda em português brasileiro. Ou seja, deixamos assim pois em alguns vídeos do português brasileiro por exemplo o código é \"pt\", já para outros está como \"pt-BR\".\n"
      ],
      "metadata": {
        "id": "7F3vYz6Q0UQB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "video_loader = YoutubeLoader.from_youtube_url(\"https://www.youtube.com/watch?v=II28i__Tf3M\",\n",
        "                                              language = [\"pt\", \"pt-BR\", \"en\"],)"
      ],
      "metadata": {
        "id": "B5OASGTpejLJ"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Usaremos o .load() para fazer a leitura e ao mesmo tempo podemos passar as informações do vídeo para uma variável"
      ],
      "metadata": {
        "id": "_fkdkSHTfoUA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "infos = video_loader.load()\n",
        "infos"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "maUY7ixzfgnP",
        "outputId": "512dfc58-83cd-4c57-9a61-9945f4a376c2"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(metadata={'source': 'II28i__Tf3M'}, page_content='Olá sejam bem-vindos a sala que você vai aprender alguns fundamentos biológicos básicos sobre as redes neurais Primeiramente você verá sobre as redes neurais humana na sequência Vamos trabalhar com as redes neurais artificiais nós temos essa imagem representa os neurônios do cérebro existem bilhões de neurônios que estão conectados base nesta imagem nós vamos discutir três principais o primeiro ponto é que existem muitos neurônios o segundo ponto é que eles estão conectados entre si e o terceiro ponto é que estes neurônio por meio dessas conexões trocam informações entre si conexão entre os neurônios dos é e é responsável pelas nossas habilidades por exemplo ver falar dar e assim por diante vamos supor que você fala o idioma português e se indica que essas conexões entre os neurônios estão criadas de forma a permitir você falar esse idioma vamos supor que você começa a aprender a falar inglês com isso novas conexões Entre esses neurônios são geradas para permitir que você consiga falar esse idioma a troca de informação entre os neurônios e permite que você aprenda novas habilidades essa é uma imagem geral que mostra essa conexão entre os neurônios vamos agora analisar neurônios of e pode ser considerado cada um desses elementos maiores com os núcleos e existem alguns componentes primeiro componente e o neurônio são os dendritos ou seja são esses terminais que recebem informações na sequência nós temos o corpo ou celular que é aqui dentro que ocorre o processamento da informação mas temos o axónio que vai transmitir essa informação processada até essa calda do neurônio que é chamado dos terminais do axónio os dados entram pelos dendritos são processados no corpo celular e são enviados para o próximo neurônio por meio dos terminais do AXN nós podemos observar essa outra figura com o neurônio um pouco menor e uma rede neural nada mais é do que a conexão entre vários neurônios perceba que por meio da ligação dos terminais do axónio com os dendritos ocorre a troca de informação entre esses dois neurônios podemos adicionar mais um neurônio mais um mais um e definimos vários outros neurônios com isso mas temos a definição da rede neural completa que simula essa imagem perceba que Agora fica mais fácil para nós observar nos componentes do neurônio a informação chega pelos dendritos é processado no corpo celular e é enviada para os outros neurônios por mim os terminais do axônio e essa conexão o a troca de informações entre os neurônios é chamada de sinapse e no cérebro humano são representadas por processos elétricos Ou seja quando uma informação é passada de neurônio para o outro o potencial elétrico do corpo celular do neurônio é alterado esses que são os principais conceitos biológicos resumido sobre as redes neurais e na próxima aula você vai entender como funcionam os neurônios artificiais obrigado e até lá')]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "O valor de \"page_content\" corresponde à transcrição em si\n",
        "\n",
        "para acessá-la devemos colocar `[0]` pois `infos` é uma lista, que nesse caso só tem o primeiro valor. O código então fica assim"
      ],
      "metadata": {
        "id": "SYGuVTRufppC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transcricao = infos[0].page_content\n",
        "transcricao"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "id": "vcj6iFdVfyrB",
        "outputId": "14f34cf2-99e7-41dd-bb27-f89978b685a0"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Olá sejam bem-vindos a sala que você vai aprender alguns fundamentos biológicos básicos sobre as redes neurais Primeiramente você verá sobre as redes neurais humana na sequência Vamos trabalhar com as redes neurais artificiais nós temos essa imagem representa os neurônios do cérebro existem bilhões de neurônios que estão conectados base nesta imagem nós vamos discutir três principais o primeiro ponto é que existem muitos neurônios o segundo ponto é que eles estão conectados entre si e o terceiro ponto é que estes neurônio por meio dessas conexões trocam informações entre si conexão entre os neurônios dos é e é responsável pelas nossas habilidades por exemplo ver falar dar e assim por diante vamos supor que você fala o idioma português e se indica que essas conexões entre os neurônios estão criadas de forma a permitir você falar esse idioma vamos supor que você começa a aprender a falar inglês com isso novas conexões Entre esses neurônios são geradas para permitir que você consiga falar esse idioma a troca de informação entre os neurônios e permite que você aprenda novas habilidades essa é uma imagem geral que mostra essa conexão entre os neurônios vamos agora analisar neurônios of e pode ser considerado cada um desses elementos maiores com os núcleos e existem alguns componentes primeiro componente e o neurônio são os dendritos ou seja são esses terminais que recebem informações na sequência nós temos o corpo ou celular que é aqui dentro que ocorre o processamento da informação mas temos o axónio que vai transmitir essa informação processada até essa calda do neurônio que é chamado dos terminais do axónio os dados entram pelos dendritos são processados no corpo celular e são enviados para o próximo neurônio por meio dos terminais do AXN nós podemos observar essa outra figura com o neurônio um pouco menor e uma rede neural nada mais é do que a conexão entre vários neurônios perceba que por meio da ligação dos terminais do axónio com os dendritos ocorre a troca de informação entre esses dois neurônios podemos adicionar mais um neurônio mais um mais um e definimos vários outros neurônios com isso mas temos a definição da rede neural completa que simula essa imagem perceba que Agora fica mais fácil para nós observar nos componentes do neurônio a informação chega pelos dendritos é processado no corpo celular e é enviada para os outros neurônios por mim os terminais do axônio e essa conexão o a troca de informações entre os neurônios é chamada de sinapse e no cérebro humano são representadas por processos elétricos Ou seja quando uma informação é passada de neurônio para o outro o potencial elétrico do corpo celular do neurônio é alterado esses que são os principais conceitos biológicos resumido sobre as redes neurais e na próxima aula você vai entender como funcionam os neurônios artificiais obrigado e até lá'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Esse primeiro exemplo é de uma legenda que foi gerada automaticamente pelo sistema de reconhecimento de fala do youtube, que no geral tende a ser bom mas pode gerar erros, então não é perfeito. Mas ainda assim, dependendo da LLM ela vai entender que se trata de um erro com base no contexto\n",
        "\n",
        "Para legendas automáticas verificamos que não houve perda considerável na compreensão, mas obviamento é esperado que uma legenda feita manualmente possua maiores chances de resultados melhores"
      ],
      "metadata": {
        "id": "_1AmxsFsf5Lq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Obter informações do vídeo\n",
        "\n",
        "Note que carregamos a legenda/transcrição mas nenhuma outra informação sobre o vídeo, o que pode ser útil depedendo do nosso objetivo.\n",
        "\n",
        "Podemos passar como parâmetro add_video_info=True (que por padrão é =False) e isso fará com que sejam retornados os metadados do vídeo, como: título, descrição, autor, visualizações, e capa)\n",
        "\n",
        "Para usar esse parâmetro você precisa ter instalado antes a biblioteca pytube"
      ],
      "metadata": {
        "id": "anF9L80yUejl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install yt-dlp"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0WX5cYaJ6elJ",
        "outputId": "068d10b9-7a3f-460d-bb41-c19b46aab157"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting yt-dlp\n",
            "  Downloading yt_dlp-2024.11.4-py3-none-any.whl.metadata (172 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/172.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m172.1/172.1 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading yt_dlp-2024.11.4-py3-none-any.whl (3.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m57.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: yt-dlp\n",
            "Successfully installed yt-dlp-2024.11.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def formatted_date(data):\n",
        "    year = data[0:4]\n",
        "    month = data[4:6]\n",
        "    day = data[6:8]\n",
        "    formatted_date = f\"{day}/{month}/{year}\"\n",
        "    return formatted_date"
      ],
      "metadata": {
        "id": "qEeMFO_h_wCh"
      },
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import yt_dlp\n",
        "\n",
        "youtube_url = \"https://www.youtube.com/watch?v=II28i__Tf3M\"\n",
        "\n",
        "ydl_opts = {}\n",
        "with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
        "    video_info = ydl.extract_info(youtube_url, download=False)\n",
        "    # title = video_info.get('title', 'Título indisponível')\n",
        "    # print(f\"Título: {title}\")\n",
        "    # print(\"Informações do vídeo:\", video_info)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MPqCaVxs6eib",
        "outputId": "44938b60-8715-4849-9d1b-86c33d1778bd"
      },
      "execution_count": 168,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[youtube] Extracting URL: https://www.youtube.com/watch?v=II28i__Tf3M\n",
            "[youtube] II28i__Tf3M: Downloading webpage\n",
            "[youtube] II28i__Tf3M: Downloading ios player API JSON\n",
            "[youtube] II28i__Tf3M: Downloading mweb player API JSON\n",
            "[youtube] II28i__Tf3M: Downloading m3u8 information\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "infos_video = f\"\"\"Informações do vídeo:\n",
        "\n",
        "Título: {video_info.get('title', 'Título indisponível')}\n",
        "Autor: {video_info.get('uploader', 'Autor indisponível')}\n",
        "Data: {formatted_date(video_info['upload_date'])}\n",
        "URL: {video_info['channel_url']}\n",
        "Transcrição: {video_info[\"description\"]}\n",
        "\"\"\"\n",
        "print(infos_video)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3-0Plh2PAWr2",
        "outputId": "017189a1-2453-4b04-d703-d885983a98fc"
      },
      "execution_count": 169,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Informações do vídeo:\n",
            "\n",
            "Título: Introdução aos fundamentos biológicos das redes neurais artificiais\n",
            "Autor: IA Expert Academy\n",
            "Data: 29/03/2022\n",
            "URL: https://www.youtube.com/channel/UCaGrIWpwjWXT6OIQh9W4Riw\n",
            "Transcrição: Nessa videoaula você será apresentado a noções introdutórias sobre os fundamentos biológicos das redes neurais artificiais. A aula faz parte do curso \"Algoritmos de Inteligência Artificial Bioinspirados\" que está disponível para assinantes IA Expert Academy. \n",
            "\n",
            "► LINKS\n",
            "Detalhes do curso: https://iaexpert.academy/courses/algoritmos-de-inteligencia-artificial-bioinspirados/\n",
            "\n",
            "Todos os nossos cursos: https://iaexpert.academy/cursos-assinatura/\n",
            "\n",
            "Saiba como se tornar um assinante da nossa plataforma de cursos online sobre inteligência artificial: https://iaexpert.academy/assinatura/\n",
            "\n",
            "Também é possível realizar o curso através da plataforma Udemy: https://www.udemy.com/course/algoritmos-de-inteligencia-artificial-bioinspirados/?referralCode=74F83D8343C970A03B2C\n",
            "\n",
            "Faça download do nosso e-book gratuito com 21 dicas de carreira em Inteligência Artificial e Machine Learning: https://iaexpert.academy/ebook-21-dicas-de-carreira-em-inteligencia-artificial-machine-learning/\n",
            "\n",
            "Não se esqueça de se inscrever no canal! https://www.youtube.com/channel/UCaGrIWpwjWXT6OIQh9W4Riw?sub_confirmation=1\n",
            "\n",
            "Siga-nos nas redes sociais:\n",
            "Instagram - https://bit.ly/3itgFsP\n",
            "Facebook - https://bit.ly/2ZxdoS2\n",
            "Linkedin - https://bit.ly/2Rnj7Fg\n",
            "Twitter - https://bit.ly/2FwaFkB\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# video_loader = YoutubeLoader.from_youtube_url(youtube_url=\"https://www.youtube.com/watch?v=II28i__Tf3M\",\n",
        "#                                                 add_video_info = True,\n",
        "#                                                language = [\"pt\", \"pt-BR\", \"en\"],)\n",
        "# # infos = video_loader.load()\n",
        "# # infos"
      ],
      "metadata": {
        "id": "21yse52Hgfmm"
      },
      "execution_count": 167,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Podemos organizar desse modo"
      ],
      "metadata": {
        "id": "f96R3cmwgBD6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# infos_video = f\"\"\"Informações do vídeo:\n",
        "\n",
        "# Título: {infos[0].metadata['title']}\n",
        "# Autor: {infos[0].metadata['author']}\n",
        "# Data: {infos[0].metadata['publish_date'][:10]}\n",
        "# URL: https://www.youtube.com/watch?v={infos[0].metadata['source']}\n",
        "\n",
        "# Transcrição: {transcricao}\n",
        "# \"\"\"\n",
        "# print(infos_video)"
      ],
      "metadata": {
        "id": "F2ZM0l2EhE0L"
      },
      "execution_count": 173,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Evbo5__itytT"
      },
      "source": [
        "## Salvando transcrição em um arquivo\n",
        "\n",
        "Esse código abre um arquivo chamado \"transcricao.txt\" em modo de escrita (\"w\") com codificação UTF-8;  dentro do bloco `with` ele grava dados no arquivo.\n",
        "\n",
        "Para cada item na variável `infos`, ele escreve o conteúdo da variável `infos_video` no arquivo. O uso do bloco with garante que o arquivo seja fechado corretamente após a gravação, mesmo que ocorra algum erro durante a execução. E aqui não precisa do `f.close()` pois o bloco with fecha o arquivo automaticamente ao finalizar"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with io.open(\"transcricao.txt\", \"w\", encoding=\"utf-8\") as f:\n",
        "  for doc in infos:\n",
        "    f.write(infos_video)"
      ],
      "metadata": {
        "id": "ncVsbSHkhX9t"
      },
      "execution_count": 119,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UsIUtB4k0EOr"
      },
      "source": [
        "## Carregamento do modelo\n",
        "\n",
        "Vamos reaproveitar as funções de carregamento que usamos nos projeos anteriores, basta copiar e colar"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def model_hf_hub(model = \"meta-llama/Meta-Llama-3-8B-Instruct\", temperature = 0.1):\n",
        "  llm = HuggingFaceHub(repo_id = model,\n",
        "                       model_kwargs={\n",
        "                           \"temperature\": temperature,\n",
        "                           \"return_full_text\": False,\n",
        "                           \"max_new_tokens\": 1024,\n",
        "                       })\n",
        "  return llm"
      ],
      "metadata": {
        "id": "Tz96zelri2Ip"
      },
      "execution_count": 120,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def model_openai(model = \"gpt-4o-mini\", temperature = 0.1):\n",
        "  llm = ChatOpenAI(model = model, temperature = temperature)\n",
        "  return llm"
      ],
      "metadata": {
        "id": "4qrY-5X2jasE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def model_ollama(model = \"phi3\", temperature = 0.1):\n",
        "  llm = ChatOllama(model = model, temperature = temperature)\n",
        "  return llm"
      ],
      "metadata": {
        "id": "-8B7J4L2joZ6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "E aqui no Colab precisar setar as variáveis de ambiente. Pode usar o .env também, especialmente se estiver executando localmente"
      ],
      "metadata": {
        "id": "A43x9uhLgIpg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = getpass.getpass()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xtbMrdU1j5YM",
        "outputId": "5e8bc343-4c55-46d0-81f1-5ecb21227fa8"
      },
      "execution_count": 121,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VysW6-CTkDP8",
        "outputId": "20a88211-59d2-4583-9495-74a2771436e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_class = \"hf_hub\" # @param [\"hf_hub\", \"openai\", \"ollama\"]\n",
        "\n",
        "if model_class == \"hf_hub\":\n",
        "  llm = model_hf_hub()\n",
        "elif model_class == \"openai\":\n",
        "  llm = model_openai\n",
        "elif model_class == \"ollama\":\n",
        "  llm = model_ollama\n"
      ],
      "metadata": {
        "id": "nZ6Nd08AktQV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a758b179-ed40-4dfb-9f3a-d744e1281974"
      },
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-120-7c8108b6e615>:2: LangChainDeprecationWarning: The class `HuggingFaceHub` was deprecated in LangChain 0.0.21 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEndpoint``.\n",
            "  llm = HuggingFaceHub(repo_id = model,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_class, llm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K97G71WXlTFi",
        "outputId": "0b0944f5-6088-4214-b075-9949e3666491"
      },
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('hf_hub',\n",
              " HuggingFaceHub(client=<InferenceClient(model='meta-llama/Meta-Llama-3-8B-Instruct', timeout=None)>, repo_id='meta-llama/Meta-Llama-3-8B-Instruct', task='text-generation', model_kwargs={'temperature': 0.1, 'return_full_text': False, 'max_new_tokens': 1024}))"
            ]
          },
          "metadata": {},
          "execution_count": 123
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "POXmLBq5yWlZ"
      },
      "source": [
        "## Criação do prompt template\n",
        "\n",
        "Vamos manter a base do prompt simples, basicamente instruindo que deve responder com base na transcrição fornecida. Você pode modificá-lo à vontade depois, para deixar mais adequado ao seu objetivo ou simplesmente para tentar alcançar melhores resultados\n",
        "\n",
        "* Aqui vamos passar o transcrição completa. Estaremos lidando com modelos que possuem uma janela grande de contexto - por exemplo o llama 3 possui algo em torno de 8k, já o chatGPT 4o por exemplo possui ainda mais. Deve ser uma capacidade suficiente de leitura de tokens de entrada para lidar com a maioria das transcrições dos vídeos, e será para todos os testados aqui.\n",
        "* Como a ideia desse projeto é criar uma ferramenta que faz o resumo / sumarização então adicionar a transcrição inteira como contexto é até uma opção mais interessante, já que para RAG é recuperado geralmente uma quantidade limite de pedaços de documento. Portanto, se fosse usado RAG teria que configurar bem os parâmetros, provavelmente escolher um valor maior de k por exemplo para recuperar mais documentos (no entanto, lembre-se que elevar muito esse valor aumenta o custo computacional da aplicação)\n",
        "* Mas caso o vídeo seja realmente grande então pode ser interessante dividir em partes. Para isso sugerimos usar o código do projeto 3, pode copiar as funções prontas que fazem as etapas de indexação e recuperação (indexing & retrieval)\n",
        "\n",
        "Além da transcrição, o prompt template irá aceitar a variável consulta, que nada mais é do que a entrada para a LLM, que pode ser uma pergunta ou instrução\n",
        "\n",
        "E o `if model_class.startswith(\"hf\"):` apenas copiamos do projeto anterior, lembrando que isso é para melhorar os resultados com a implementação via Hugging Face Hub, que até o momento funciona melhor se especificarmos manualmente os tokens de início e fim. Aqui o template é do llama 3.x, mas for usar outro modelo open source que exija template diferente então lembre de mudar.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "system_prompt = \"Você é um assistente virtual prestativo e deve responder a uma consulta com base na transcrição de um vídeo, que será fornecida abaixo.\"\n",
        "\n",
        "inputs = \"Consulta: {consulta} \\n Transcrição: {transcricao}\"\n",
        "\n",
        "if model_class.startswith(\"hf\"):\n",
        "  user_prompt = \"<|begin_of_text|><|start_header_id|>user<|end_header_id|>\\n{}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\".format(inputs)\n",
        "else:\n",
        "  user_prompt = \"{}\".format(inputs)\n",
        "\n",
        "prompt_template = ChatPromptTemplate.from_messages([(\"system\", system_prompt), (\"user\", user_prompt)])"
      ],
      "metadata": {
        "id": "iTi4bJdsnSvZ"
      },
      "execution_count": 124,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_template"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RKDHaVIeoQD8",
        "outputId": "bf1bba95-d5ac-4996-b3c7-5aa1b9757145"
      },
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ChatPromptTemplate(input_variables=['consulta', 'transcricao'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='Você é um assistente virtual prestativo e deve responder a uma consulta com base na transcrição de um vídeo, que será fornecida abaixo.'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['consulta', 'transcricao'], input_types={}, partial_variables={}, template='<|begin_of_text|><|start_header_id|>user<|end_header_id|>\\nConsulta: {consulta} \\n Transcrição: {transcricao}<|eot_id|><|start_header_id|>assistant<|end_header_id|>'), additional_kwargs={})])"
            ]
          },
          "metadata": {},
          "execution_count": 125
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l4gBdHEc0WXz"
      },
      "source": [
        "## Criação da chain\n",
        "\n",
        "Nossa chain ficará assim"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chain = prompt_template | llm | StrOutputParser()"
      ],
      "metadata": {
        "id": "DIjtm5a2z8Yd"
      },
      "execution_count": 126,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zTMbsbDxorCU"
      },
      "source": [
        "## Geração da resposta\n",
        "\n",
        "Por fim, vamos gerar o resultado, fornecendo como parâmetro a transcrição e a consulta que queremos (podendo ser pergunta, instrução, etc.)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "res = chain.invoke({\"transcricao\": transcricao, \"consulta\": \"resuma\"})\n",
        "print(res)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XMXxmToB0D1f",
        "outputId": "4a406a30-432f-44b2-d98e-4c6ca4255963"
      },
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Aqui está um resumo da transcrição:\n",
            "\n",
            "A aula começa apresentando a estrutura do cérebro humano, com bilhões de neurônios conectados entre si. Os neurônios são responsáveis pelas habilidades humanas, como falar, ver e ouvir. A troca de informações entre os neurônios é feita por meio de conexões, chamadas sinapses.\n",
            "\n",
            "O neurônio é composto por três principais componentes: dendritos, corpo celular e axônio. Os dendritos recebem informações, o corpo celular processa a informação e o axônio transmite a informação processada para o próximo neurônio.\n",
            "\n",
            "A rede neural é formada pela conexão entre vários neurônios, onde a troca de informações ocorre por meio da sinapse. A sinapse é representada por processos elétricos no cérebro humano, onde o potencial elétrico do corpo celular do neurônio é alterado quando uma informação é passada de um neurônio para outro.\n",
            "\n",
            "A aula conclui apresentando os principais conceitos biológicos sobre as redes neurais, preparando o aluno para entender como funcionam os neurônios artificiais na próxima aula.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Podemos melhorar esse prompt (consulta), deixando algo como `\"sumarize de forma clara de entender`"
      ],
      "metadata": {
        "id": "aB-naQ5Ih1Hk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "res = chain.invoke({\"transcricao\": transcricao, \"consulta\": \"sumarize de forma clara de entender\"})\n",
        "print(res)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_shbNeVT0daZ",
        "outputId": "f8d980d1-fefa-48dc-d342-c67dd76be81c"
      },
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Aqui está uma resumo claro e fácil de entender da transcrição:\n",
            "\n",
            "As redes neurais são compostas por bilhões de neurônios que se conectam entre si e trocam informações. Existem três principais pontos:\n",
            "\n",
            "1. Existem muitos neurônios.\n",
            "2. Eles estão conectados entre si.\n",
            "3. Essas conexões permitem que os neurônios troquem informações entre si.\n",
            "\n",
            "Essas conexões são responsáveis pelas nossas habilidades, como falar, ver e ouvir. Quando aprendemos uma habilidade nova, novas conexões são criadas entre os neurônios para permitir que aprendamos.\n",
            "\n",
            "Um neurônio é composto por:\n",
            "\n",
            "* Dendritos: recebem informações\n",
            "* Corpo celular: processa a informação\n",
            "* Axónio: transmite a informação processada para outro neurônio\n",
            "\n",
            "A troca de informações entre neurônios é chamada de sinapse e ocorre quando o potencial elétrico do corpo celular do neurônio é alterado.\n",
            "\n",
            "Em resumo, as redes neurais são compostas por neurônios que se conectam e trocam informações, permitindo que aprendamos e desenvolvamos habilidades.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "res = chain.invoke({\"transcricao\": transcricao, \"consulta\": \"explique em 1 frase sobre o que fala esse vídeo\"})\n",
        "print(res)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EwS4t_5V0omz",
        "outputId": "09a15461-ac1f-44f2-bf10-922666e008c8"
      },
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "O vídeo explica os fundamentos biológicos das redes neurais, destacando a estrutura e funcionamento dos neurônios humanos e a troca de informações entre eles.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "res = chain.invoke({\"transcricao\": transcricao, \"consulta\": \"liste os temas desse video\"})\n",
        "print(res)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gF_4_4Yq0wTg",
        "outputId": "d2f5a910-28d3-4606-dc91-81d6b6f762dd"
      },
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Aqui estão os temas do vídeo:\n",
            "\n",
            "1. Redes neurais humanas\n",
            "2. Componentes do neurônio (dendritos, corpo celular, axónio, terminais do axónio)\n",
            "3. Sinapse (troca de informações entre neurônios)\n",
            "4. Processamento de informações nos neurônios\n",
            "5. Redes neurais artificiais\n",
            "6. Aprendizado e formação de conexões entre neurônios\n",
            "7. Função do cérebro humano em relação às redes neurais.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vI-OaqiUzynG"
      },
      "source": [
        "## Tradução da transcrição\n",
        "\n",
        "Para os modelos mais modernos não é necessário traduzir antes, pode carregar a transcrição no idioma desejado e passar para a LLM mesmo que no idioma diferente daquele que você escreveu as instruções no prompt template, isso porque o modelo deve ser capaz de entender.\n",
        "\n",
        "Mas também é possível traduzir a transcrição usando essa mesma ferramenta.\n",
        "Isso pode ser muito útil caso o modelo que esteja trabalhando não funcione bem para múltiplos idiomas.\n",
        "\n",
        "Para implementar isso, basta definirmos para o parâmetro translation o código do idioma para o qual desejamos traduzir.\n",
        "Por exemplo para o francês ficaria assim"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# url_video = \"https://www.youtube.com/watch?v=II28i__Tf3M\"\n",
        "\n",
        "# video_loader = YoutubeLoader.from_youtube_url(\n",
        "#     url_video,\n",
        "#     add_video_info=True,\n",
        "#     language=[\"pt\", \"en\"],\n",
        "#     translation=\"fr\",\n",
        "# )\n",
        "\n",
        "# infos = video_loader.load()\n",
        "# transcricao = infos[0].page_content\n",
        "# transcricao"
      ],
      "metadata": {
        "id": "qNv8bG4W14iR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nIBmX2hrz3JT"
      },
      "source": [
        "## Junção da pipeline em funções\n",
        "\n",
        "Para deixar mais prático e evitar repetições do código vamos reunir toda a nossa lógica em funções, assim não vai ser mais necessário ficar copiando e colando o código toda vez que for testar em outro vídeo"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def llm_chain(model_class):\n",
        "  system_prompt = \"Você é um assistente virtual prestativo e deve responder a uma consulta com base na transcrição de um vídeo, que será fornecida abaixo.\"\n",
        "\n",
        "  inputs = \"Consulta: {consulta} \\n Transcrição: {transcricao}\"\n",
        "\n",
        "  if model_class.startswith(\"hf\"):\n",
        "      user_prompt = \"<|begin_of_text|><|start_header_id|>user<|end_header_id|>\\n{}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\".format(inputs)\n",
        "  else:\n",
        "      user_prompt = \"{}\".format(inputs)\n",
        "\n",
        "  prompt_template = ChatPromptTemplate.from_messages([\n",
        "      (\"system\", system_prompt),\n",
        "      (\"user\", user_prompt)\n",
        "  ])\n",
        "\n",
        "  ### Carregamento da LLM\n",
        "  if model_class == \"hf_hub\":\n",
        "      llm = model_hf_hub()\n",
        "  elif model_class == \"openai\":\n",
        "      llm = model_openai()\n",
        "  elif model_class == \"ollama\":\n",
        "      llm = model_ollama()\n",
        "\n",
        "  chain = prompt_template | llm | StrOutputParser()\n",
        "\n",
        "  return chain"
      ],
      "metadata": {
        "id": "uwUHiqpfNrfV"
      },
      "execution_count": 170,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_video_info(url_video, language=\"pt\", translation=None):\n",
        "\n",
        "  video_loader = YoutubeLoader.from_youtube_url(\n",
        "      url_video,\n",
        "      add_video_info=True,\n",
        "      language=language,\n",
        "      translation=translation,\n",
        "  )\n",
        "\n",
        "  infos = video_loader.load()[0]\n",
        "  metadata = infos.metadata\n",
        "  transcript = infos.page_content\n",
        "\n",
        "  return transcript, metadata"
      ],
      "metadata": {
        "id": "eGkSmn9xN1s-"
      },
      "execution_count": 171,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_transcription(url_video):\n",
        "  ydl_opts = {}\n",
        "  with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
        "      video_info = ydl.extract_info(url_video, download=False,\n",
        "                                    )\n",
        "  transcript = video_info[\"description\"]\n",
        "  return transcript"
      ],
      "metadata": {
        "id": "GNegWMcvNu_0"
      },
      "execution_count": 209,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vamos testar abaixo"
      ],
      "metadata": {
        "id": "7OUUnSy_iDEo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# transcript, metadata = get_video_info(\"https://www.youtube.com/watch?v=II28i__Tf3M\")\n",
        "transcript = get_transcription(\"https://www.youtube.com/watch?v=II28i__Tf3M\")\n",
        "transcript"
      ],
      "metadata": {
        "id": "yKQLLDGGOCbD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "outputId": "7d74d559-3250-4286-ae05-877551e51e19"
      },
      "execution_count": 210,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[youtube] Extracting URL: https://www.youtube.com/watch?v=II28i__Tf3M\n",
            "[youtube] II28i__Tf3M: Downloading webpage\n",
            "[youtube] II28i__Tf3M: Downloading ios player API JSON\n",
            "[youtube] II28i__Tf3M: Downloading mweb player API JSON\n",
            "[youtube] II28i__Tf3M: Downloading m3u8 information\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Nessa videoaula você será apresentado a noções introdutórias sobre os fundamentos biológicos das redes neurais artificiais. A aula faz parte do curso \"Algoritmos de Inteligência Artificial Bioinspirados\" que está disponível para assinantes IA Expert Academy. \\n\\n► LINKS\\nDetalhes do curso: https://iaexpert.academy/courses/algoritmos-de-inteligencia-artificial-bioinspirados/\\n\\nTodos os nossos cursos: https://iaexpert.academy/cursos-assinatura/\\n\\nSaiba como se tornar um assinante da nossa plataforma de cursos online sobre inteligência artificial: https://iaexpert.academy/assinatura/\\n\\nTambém é possível realizar o curso através da plataforma Udemy: https://www.udemy.com/course/algoritmos-de-inteligencia-artificial-bioinspirados/?referralCode=74F83D8343C970A03B2C\\n\\nFaça download do nosso e-book gratuito com 21 dicas de carreira em Inteligência Artificial e Machine Learning: https://iaexpert.academy/ebook-21-dicas-de-carreira-em-inteligencia-artificial-machine-learning/\\n\\nNão se esqueça de se inscrever no canal! https://www.youtube.com/channel/UCaGrIWpwjWXT6OIQh9W4Riw?sub_confirmation=1\\n\\nSiga-nos nas redes sociais:\\nInstagram - https://bit.ly/3itgFsP\\nFacebook - https://bit.ly/2ZxdoS2\\nLinkedin - https://bit.ly/2Rnj7Fg\\nTwitter - https://bit.ly/2FwaFkB'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 210
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# metadata, transcript"
      ],
      "metadata": {
        "id": "AB_UJpj5OF-r"
      },
      "execution_count": 208,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Aqui aproveitamos para adicionar um Tratamento de erro com Try Catch, pois caso não haja uma transcrição para esse vídeo será retornado um erro (possivelmente será esse: `IndexError: list index out of range`), com isso não será possível fazer os processamentos seguintes. Por isso programos aqui para o programa parar interromper a execuão se esse for caso"
      ],
      "metadata": {
        "id": "pMjY_vFjkFtX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def interpret_video(url, query=\"resuma\", model_class=\"hf_hub\", language=\"pt\", translation=None):\n",
        "\n",
        "  try:\n",
        "    transcript = get_transcription(url_video)\n",
        "    # transcript, metadata = get_video_info(url, language, translation)\n",
        "\n",
        "    chain = llm_chain(model_class)\n",
        "\n",
        "    res = chain.invoke({\"transcricao\": transcript, \"consulta\": query})\n",
        "    print(res)\n",
        "\n",
        "  except Exception as e:\n",
        "    print(\"Erro ao carregar transcrição\")\n",
        "    print(e)"
      ],
      "metadata": {
        "id": "a36jNBjjOUl0"
      },
      "execution_count": 211,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xw9rCl0EGQ9v"
      },
      "source": [
        "## Geração final\n",
        "\n",
        "Podemos definir uma interface mais apresentável no Colab através dos comandos para deixar as variáveis em formato de valores de formulário.\n",
        "\n",
        "Ideias do que adicionar à query:\n",
        "\n",
        "* `sumarize de forma clara de entender`\n",
        "* `liste os temas desse vídeo`\n",
        "* `explique em 1 frase sobre o que fala esse vídeo`"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "url_video = \"https://www.youtube.com/watch?v=II28i__Tf3M\" # @param {type:\"string\"}\n",
        "query_user = \"sumarize de forma clara de entender\" # @param {type:\"string\"}\n",
        "model_class = \"openai\" # @param [\"hf_hub\", \"openai\", \"ollama\"]\n",
        "language = [\"pt\", \"pt-BR\", \"en\"] # @param {type:\"string\"}"
      ],
      "metadata": {
        "id": "Yp21Wx-zOyzg"
      },
      "execution_count": 212,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "interpret_video(url_video, query_user, model_class, language)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U5bGa9xhO6zS",
        "outputId": "9498964d-f671-4d25-e631-2bf3979f93c8"
      },
      "execution_count": 213,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[youtube] Extracting URL: https://www.youtube.com/watch?v=II28i__Tf3M\n",
            "[youtube] II28i__Tf3M: Downloading webpage\n",
            "[youtube] II28i__Tf3M: Downloading ios player API JSON\n",
            "[youtube] II28i__Tf3M: Downloading mweb player API JSON\n",
            "[youtube] II28i__Tf3M: Downloading m3u8 information\n",
            "Erro ao carregar transcrição\n",
            "name 'model_openai' is not defined\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "url_video = \"https://www.youtube.com/watch?v=rEE8ERGKsqo\" # @param {type:\"string\"}\n",
        "query_user = \"sumarize de forma clara de entender\" # @param {type:\"string\"}\n",
        "model_class = \"hf_hub\" # @param [\"hf_hub\", \"openai\", \"ollama\"]\n",
        "language = [\"pt\", \"pt-BR\", \"en\"] # @param {type:\"string\"}\n",
        "\n",
        "interpret_video(url_video, query_user, model_class, language)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6E16t3wFQUXp",
        "outputId": "a2b48b88-962f-4472-c90f-3e4234359e68"
      },
      "execution_count": 214,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[youtube] Extracting URL: https://www.youtube.com/watch?v=rEE8ERGKsqo\n",
            "[youtube] rEE8ERGKsqo: Downloading webpage\n",
            "[youtube] rEE8ERGKsqo: Downloading ios player API JSON\n",
            "[youtube] rEE8ERGKsqo: Downloading mweb player API JSON\n",
            "[youtube] rEE8ERGKsqo: Downloading m3u8 information\n",
            "\n",
            "\n",
            "Resumo:\n",
            "\n",
            "O vídeo é sobre astronomia e visa ajudar aqueles que gostam do assunto mas se sentem perdidos ao ler sobre ele. O conteúdo do vídeo é destinado a ensinar o básico da ciência dos astros e é recomendado que os espectadores preparem prints e cadernos de anotações para acompanhar o vídeo.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SMsC4SD56fjn"
      },
      "source": [
        "## Explorando mais\n",
        "\n",
        "Vamos deixar nossa aplicação mais interessante. Podemos fazer mais de uma consulta/query de uma vez por vídeo.\n",
        "\n",
        "* Para cada vídeo informado, podemos definir para exibir informações como o titulo dele;\n",
        "* e logo abaixo um resumo em um paragrafo;\n",
        "* depois uma lista de temas abordados, etc.\n",
        "\n",
        "No Colab temos um modo interessante de fazer isso, que é através do Markdown.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exemplo com Markdown\n",
        "\n",
        "Markdown é um formato de linguagem de marcação muito adotada pela comunidade por ser simples e leve, permitindo criar texto formatado com uso de símbolos especiais, como asteriscos e colchetes, em vez de tags de HTML. No Google Colab, o uso de markdown pode tornar a visualização do texto mais interessante e fácil de ler, facilitando a compreensão e a apresentação de informações. Por exemplo, usando markdown, você pode deixar um texto em *itálico* ao deixar dentro de asteriscos, ou **negrito** se deixar ele dentro de asteriscos duplos. Também podemos adicionar títulos com diferentes níveis, por exemplo para nível 1,2,3 basta colocar antes da frase `#` `##` ou `###` respectivamente\n",
        "\n",
        "> Mais sobre a sintaxe aqui: https://www.markdownguide.org/basic-syntax/"
      ],
      "metadata": {
        "id": "_kqBFxkSg0qM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "texto = \"\"\"\n",
        "### Título\n",
        "descrição em **destaque** *aqui...*\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "7NwcyF-6yIh7"
      },
      "execution_count": 216,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Markdown\n",
        "\n",
        "display(Markdown(texto))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 83
        },
        "id": "avEBI_aAyXcB",
        "outputId": "1f9e0316-8924-4eb0-8198-96ce438b3c54"
      },
      "execution_count": 217,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "\n### Título\ndescrição em **destaque** *aqui...*\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "E abaixo em forma de lista por exemplo\n",
        "\n",
        "Com isso, se pedirmos por exemplo pra LLM retornar uma lista então ficará mais apresentável também, já que ela irá retornar nesse formato com * no inicio de cada item, já que é um padrão comum\n",
        "\n",
        "Nos projetos em que usamos os Streamlit talvez tenha notada que já ficou automaticamente dessem modo, pois a interface já interpreta corretamente markdown"
      ],
      "metadata": {
        "id": "Zm832xwVkdHS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lista = \"\"\"\n",
        "* item\n",
        "* item\n",
        "* item\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "_FyGdQBkyo2X"
      },
      "execution_count": 218,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display(Markdown(lista))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "id": "W1-ehmxfyrNr",
        "outputId": "65ba18eb-acde-4699-b57e-15bd4a0a99d4"
      },
      "execution_count": 219,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "\n* item\n* item\n* item\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Finalização do código\n",
        "\n",
        "Copiamos do código que fizemos antes, só mudando de infos[0].metadata para metadata\n",
        "\n",
        "e ao invés do print() normal, vamos colocar no lugar display(Markdown()) para deixar mais apresentável\n",
        "\n",
        "Como resposta, teremos:\n",
        "* Informações do vídeo - que são os metadados: título, autor, data, URL.\n",
        "\n",
        "*  Sobre o que fala o vídeo - resumo de 1 frase, para contextualizarmos bem rapidamente\n",
        "\n",
        "* Temas - listagem dos principais temas desse vídeo\n",
        "\n",
        "* Resposta para a consulta - que é a resposta para a consulta personalizada que fizemos, que pode ser uma pergunta ou instrução\n",
        "\n",
        "Aqui você pode customizar à vontade depois, deixar com as consultas que achar mais conveniente para o objetivo de sua aplicação\n",
        "\n",
        "Você poderia também separar em duas funções: uma para exibir junto as consultas fixas (informações do vídeo, resumo e temas) e outra para exibir a consulta personalizada, podendo deixar em formato de chat, igual feito no projeto 1 e 2.\n",
        "\n",
        "mas aqui estamos deixando mais simples e rápido, portanto ficou desse modo"
      ],
      "metadata": {
        "id": "zL2gTVHyaXvq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def interpret_video(url, query=\"liste os temas desse vídeo\", model_class=\"hf_hub\", language=\"pt\", translation=None):\n",
        "\n",
        "  try:\n",
        "    # transcript, metadata = get_video_info(url, language, translation)\n",
        "\n",
        "    ydl_opts = {}\n",
        "    with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
        "      video_info = ydl.extract_info(url_video, download=False)\n",
        "\n",
        "    transcript = video_info[\"description\"]\n",
        "\n",
        "    infos_video = f\"\"\"## Informações do vídeo\n",
        "\n",
        "    Título: {video_info.get('title', 'Título indisponível')}\n",
        "    Autor: {video_info.get('uploader', 'Autor indisponível')}\n",
        "    Data: {formatted_date(video_info['upload_date'])}\n",
        "    URL: {video_info['channel_url']}\n",
        "    \"\"\"\n",
        "\n",
        "    display(Markdown(infos_video))\n",
        "\n",
        "    chain = llm_chain(model_class)\n",
        "\n",
        "    t = \"\\n## Sobre o que fala o vídeo \\n\"\n",
        "    res = chain.invoke({\"transcricao\": transcript, \"consulta\": \"explique em 1 frase sobre o que fala esse vídeo. responda direto com a frase\"})\n",
        "    display(Markdown(t + res))\n",
        "\n",
        "    t = \"\\n## Temas \\n\"\n",
        "    res = chain.invoke({\"transcricao\": transcript, \"consulta\": \"lista os principais temas desse vídeo\"})\n",
        "    display(Markdown(t + res))\n",
        "\n",
        "    t = \"\\n## Resposta para a consulta \\n\"\n",
        "    res = chain.invoke({\"transcricao\": transcript, \"consulta\": query})\n",
        "    display(Markdown(t + res))\n",
        "\n",
        "  except Exception as e:\n",
        "    print(\"Erro ao carregar transcrição\")\n",
        "    print(e)"
      ],
      "metadata": {
        "id": "2LZyZPj6y0JO"
      },
      "execution_count": 224,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "url_video = \"https://www.youtube.com/watch?v=rEE8ERGKsqo\" # @param {type:\"string\"}\n",
        "query_user = \"sumarize de forma clara de entender\" # @param {type:\"string\"}\n",
        "model_class = \"hf_hub\" # @param [\"hf_hub\", \"openai\", \"ollama\"]\n",
        "language = [\"pt\", \"pt-BR\", \"en\"] # @param {type:\"string\"}\n",
        "\n",
        "interpret_video(url_video, query_user, model_class, language)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        },
        "id": "-eToCwopz_zG",
        "outputId": "7a29ee44-2cdc-4491-f668-c380bb1e5f22"
      },
      "execution_count": 225,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[youtube] Extracting URL: https://www.youtube.com/watch?v=rEE8ERGKsqo\n",
            "[youtube] rEE8ERGKsqo: Downloading webpage\n",
            "[youtube] rEE8ERGKsqo: Downloading ios player API JSON\n",
            "[youtube] rEE8ERGKsqo: Downloading mweb player API JSON\n",
            "[youtube] rEE8ERGKsqo: Downloading m3u8 information\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "## Informações do vídeo\n\n    Título: TUDO QUE VOCÊ PRECISA SABER PRA ENTENDER O BÁSICO SOBRE ASTRONOMIA\n    Autor: Universo Interessado\n    Data: 26/03/2023\n    URL: https://www.youtube.com/channel/UCtJAiOB45Wil79b4zESqULg\n    "
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "\n## Sobre o que fala o vídeo \n\n\nO vídeo é sobre como aprender os fundamentos da astronomia de forma fácil e prática."
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "\n## Temas \n\n\nOs principais temas desse vídeo são:\n\n1. Astronomia\n2. Ciência dos astros\n3. Entender o básico da astronomia"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "\n## Resposta para a consulta \nassistant"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "url_video = \"https://www.youtube.com/watch?v=n9u-TITxwoM\" # @param {type:\"string\"}\n",
        "query_user = \"sumarize de forma clara de entender\" # @param {type:\"string\"}\n",
        "model_class = \"hf_hub\" # @param [\"hf_hub\", \"openai\", \"ollama\"]\n",
        "language = [\"pt\", \"pt-BR\", \"en\"] # @param {type:\"string\"}\n",
        "\n",
        "interpret_video(url_video, query_user, model_class, language)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 673
        },
        "id": "Wlm_3Zao1jvD",
        "outputId": "02697578-374b-4a42-8f9b-6208c1ad1ef4"
      },
      "execution_count": 226,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[youtube] Extracting URL: https://www.youtube.com/watch?v=n9u-TITxwoM\n",
            "[youtube] n9u-TITxwoM: Downloading webpage\n",
            "[youtube] n9u-TITxwoM: Downloading ios player API JSON\n",
            "[youtube] n9u-TITxwoM: Downloading mweb player API JSON\n",
            "[youtube] n9u-TITxwoM: Downloading m3u8 information\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "## Informações do vídeo\n\n    Título: The six degrees | Kevin Bacon | TEDxMidwest\n    Autor: TEDx Talks\n    Data: 28/06/2012\n    URL: https://www.youtube.com/channel/UCsT0YIqwnpJCM-mx7-gSA4Q\n    "
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "\n## Sobre o que fala o vídeo \n\n\nO vídeo fala sobre a carreira e filantropia do ator Kevin Bacon e a fundação do TEDx, um programa de eventos que promove a discussão e conexão entre pessoas."
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "\n## Temas \n\n\nOs principais temas desse vídeo são:\n\n1. Kevin Bacon\n2. Cinema\n3. Cultura popular\n4. Caridade\n5. SixDegrees.org\n6. TEDx\n7. Eventos de palestras\n8. Comunicação e conexão entre pessoas"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "\n## Resposta para a consulta \n\n\nResumo:\n\nKevin Bacon é um ator que participou de filmes influentes e icônicos. Ele criou a SixDegrees.org, uma iniciativa filantrópica que conecta pessoas a organizações de caridade e entre si para fazer uma diferença. O TEDx é um programa que organiza eventos locais e autogerenciados que trazem pessoas juntas para compartilhar experiências TED-like e estimular discussões e conexões profundas. Os eventos TEDx são autogerenciados, mas estão sujeitos a certas regras e regulamentações."
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "url_video = \"https://www.youtube.com/watch?v=XXcHDy3QH-E\" # @param {type:\"string\"}\n",
        "query_user = \"sumarize de forma clara de entender\" # @param {type:\"string\"}\n",
        "model_class = \"hf_hub\" # @param [\"hf_hub\", \"openai\", \"ollama\"]\n",
        "language = [\"pt\", \"pt-BR\", \"en\"] # @param {type:\"string\"}\n",
        "\n",
        "interpret_video(url_video, query_user, model_class, language)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 603
        },
        "id": "aZSi55V-1w8o",
        "outputId": "696b24e2-c0fe-49e1-d321-e03d1a9d2758"
      },
      "execution_count": 227,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[youtube] Extracting URL: https://www.youtube.com/watch?v=XXcHDy3QH-E\n",
            "[youtube] XXcHDy3QH-E: Downloading webpage\n",
            "[youtube] XXcHDy3QH-E: Downloading ios player API JSON\n",
            "[youtube] XXcHDy3QH-E: Downloading mweb player API JSON\n",
            "[youtube] XXcHDy3QH-E: Downloading m3u8 information\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "## Informações do vídeo\n\n    Título: Como teoria do caos e efeito borboleta ajudam a explicar Universo\n    Autor: BBC News Brasil\n    Data: 21/08/2022\n    URL: https://www.youtube.com/channel/UCthbIFAxbXTTQEC7EcQvP1Q\n    "
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "\n## Sobre o que fala o vídeo \n\n\nA teoria do caos questiona a visão determinista de que o comportamento de um objeto pode ser previsto com facilidade, introduzindo um elemento de incerteza na nossa compreensão do Universo."
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "\n## Temas \n\n\nOs principais temas desse vídeo são:\n\n1. Teoria do caos\n2. Determinismo e incerteza\n3. Física clássica e leis de Newton\n4. Previsibilidade e comportamento dos objetos\n5. Influência da teoria do caos na vida cotidiana"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "\n## Resposta para a consulta \n\n\nResumo:\n\nA teoria do caos questiona a visão determinista de que, com conhecimento do estado atual de um objeto, podemos prever com facilidade seu comportamento futuro. Isso significa que nem tudo é previsível e que o comportamento do universo não é sempre linear e previsível, como era pensado anteriormente. A teoria do caos não é a mesma coisa que desordem, mas sim um conceito que introduz incerteza na nossa compreensão do universo."
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Reconhecimento de fala\n",
        "\n",
        "Se o vídeo não tiver uma transcrição disponível, será necessário gerar uma de forma automática utilizando um modelo de reconhecimento de fala, também conhecido como Speech-to-Text (STT). Esses modelos convertem fala em texto a partir de arquivos de áudio, permitindo que o conteúdo do vídeo seja transcrito para ser processado pela nossa aplicação de sumarização.\n",
        "\n",
        "Um exemplo popular de modelo de Speech-to-Text é o [Whisper](https://openai.com/index/whisper/), da OpenAI, que oferece uma solução robusta para transcrição automática. Os preços e detalhes sobre o uso desse modelo podem ser encontrados na página de \"[pricing](https://openai.com/api/pricing/)\" da OpenAI. No entanto, neste projeto, optamos por não utilizá-lo, pois todos os vídeos testados já possuíam transcrições, muitas vezes geradas automaticamente pelo YouTube. Essa abordagem economiza processamento, já que o foco principal foi a implementação de modelos de linguagem grandes (LLMs) e a exploração de ferramentas do Langchain.\n",
        "\n",
        "* Se você precisar integrar um serviço de transcrição, a implementação é simples, podendo ser feita com uma chamada de função. A documentação do Langchain oferece instruções detalhadas sobre como realizar essa integração aqui: https://js.langchain.com/v0.2/docs/integrations/document_loaders/file_loaders/openai_whisper_audio/.\n",
        "\n",
        "* Na verdade você tem a liberdade de escolher qualquer serviço ou código para realizar o reconhecimento de fala. Mesmo que o serviço não se integre diretamente ao Langchain, isso não é um problema, pois o essencial é obter o texto final. No final, o que você obtém é um texto normal, que pode ser armazenado em um arquivo de texto ou diretamente em uma variável.\n",
        "\n",
        "* Entretanto, se desejar aproveitar soluções prontas dentro do Langchain, você pode utilizar o Whisper da OpenAI ou outras opções como o [GoogleSpeechToText](https://python.langchain.com/v0.2/docs/integrations/document_loaders/google_speech_to_text/) e o [AssemblyAI Audio Transcripts](https://python.langchain.com/v0.2/docs/integrations/document_loaders/assemblyai/), que também são altamente eficazes e fáceis de integrar ao langchain."
      ],
      "metadata": {
        "id": "hJy57aqAkxgx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Indo além 🚀\n",
        "\n",
        "1. Conforme mencionado anteriormente, para vídeos muito longos ou transcrições maiores, pode ser necessário dividir a transcrição em partes menores e aplicar técnicas de indexação e recuperação utilizando RAG.\n",
        " * Isso é essencial caso o vídeo que deseja processar possua horas por exemplo - talvez modelos muito modernos e com janela de contexto maior consigam lidar, mas mesmo que consigam pode ser interessante aplicar essas técnicas, principalmente caso o que busque não seja a sumarização mas sim algo próximo do nosso projeto de perguntas e respostas com documentos, que será visto no projeto 3.\n",
        " * Caso deseje seguir esse caminho, basta reutilizar o código já pronto no projeto 3, que lida com esse tipo de segmentação e recuperação de forma eficiente. Assim, você poderá manter a integridade da transcrição, otimizando o processamento e a geração de respostas mais precisas, mesmo com grandes volumes de dados.\n",
        "\n",
        "2. Como ideia adicional ou desafio: é possível personalizar este projeto para atender a outras necessidades, ou ainda usar a sumarização como uma etapa posterior dentro de uma pipeline maior.\n",
        "  * Um exemplo seria o uso da ferramenta [YouTubeSearchTool](https://python.langchain.com/v0.2/docs/integrations/tools/youtube//) do Langchain, que permite buscar automaticamente uma lista de URLs de vídeos no YouTube com base em um tema ou palavra-chave fornecida pelo usuário.\n",
        "  * Nessa abordagem, você poderia implementar uma aplicação que solicita um termo de busca e, em seguida, utiliza essa ferramenta para buscar vídeos relevantes, retornando em uma lista. Por fim, basta criar um laço de repetição que execute a função interpret_video (que criamos nesse projeto) para cada vídeo da lista, realizando assim a sumarização de múltiplos vídeos associados a um tema de forma automatizada.\n",
        "\n",
        "3. Além disso, é possível integrar essa funcionalidade a uma interface interativa com ferramentas como Streamlit, que permite criar facilmente interfaces gráficas.\n",
        " * Os métodos para essa integração estão descritos detalhadamente nos projetos 2 e 3, caso queira expandir a aplicação.\n",
        " * Embora, neste exemplo, tenhamos optado por usar o Google Colab pela conveniência e para demonstrar a exibição com Markdown, a migração para uma interface mais robusta pode ser feita com facilidade e oferecer uma experiência mais fluida para o usuário final caso deseje publicar essa aplicação.\n"
      ],
      "metadata": {
        "id": "MFa7QY1mkzBx"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}